{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875187a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-06T13:37:42.581569Z",
     "iopub.status.busy": "2026-01-06T13:37:42.581254Z",
     "iopub.status.idle": "2026-01-06T13:37:48.279424Z",
     "shell.execute_reply": "2026-01-06T13:37:48.278458Z"
    },
    "papermill": {
     "duration": 5.704438,
     "end_time": "2026-01-06T13:37:48.280812",
     "exception": false,
     "start_time": "2026-01-06T13:37:42.576374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, random, math, time, json\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "SR_LIST = [16000]\n",
    "SR_LIST = sorted(set(int(s) for s in SR_LIST)) \n",
    "SR = SR_LIST[-1] \n",
    "\n",
    "if 'VERBOSE_CONFIG' not in globals():\n",
    "    VERBOSE_CONFIG = True\n",
    "\n",
    "NOISE_COLOR = \"white\"  \n",
    "N_MFCC = 25           \n",
    "N_MELS = 40           \n",
    "ARCH = \"transformer\"  \n",
    "\n",
    "def mfcc_params_for_sr(sr: int):\n",
    "    sr = int(sr)\n",
    "    if sr == 16000:\n",
    "        return {\"n_fft\": 512, \"win_length\": 400, \"hop_length\": 160}\n",
    "    if sr == 8000:\n",
    "        return {\"n_fft\": 256, \"win_length\": 200, \"hop_length\": 80}\n",
    "    win = int(sr * 0.025)\n",
    "    hop = int(sr * 0.010)\n",
    "    def _next_pow2(x):\n",
    "        p = 1\n",
    "        while p < x:\n",
    "            p <<= 1\n",
    "        return p\n",
    "    return {\"n_fft\": _next_pow2(win), \"win_length\": win, \"hop_length\": hop}\n",
    "\n",
    "if \"COMMIT_MODE\" not in globals():\n",
    "    COMMIT_MODE = False\n",
    "\n",
    "def set_seed(seed: int = 42, deterministic: bool = True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = bool(deterministic)\n",
    "    torch.backends.cudnn.benchmark = not bool(deterministic)\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "PIN_MEMORY = True if USE_CUDA else False\n",
    "NON_BLOCK = True if USE_CUDA else False\n",
    "\n",
    "if not COMMIT_MODE and VERBOSE_CONFIG:\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "WHITE_NOISE_FILE = \"white_noise.wav\"\n",
    "PINK_NOISE_FILE  = \"pink_noise.wav\"\n",
    "\n",
    "def resolve_root_dir():\n",
    "    candidates = []\n",
    "    env = os.environ.get(\"SPEECH_COMMANDS_ROOT\")\n",
    "    if env:\n",
    "        candidates.append(env)\n",
    "    candidates += [\n",
    "        \"/kaggle/input/speech-commands\",\n",
    "        os.path.join(os.getcwd(), \"data\", \"speech-commands\"),\n",
    "        os.path.join(os.getcwd(), \"speech-commands\"),\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p and os.path.isdir(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "ROOT_DIR = resolve_root_dir()\n",
    "\n",
    "def resolve_noise_dir(root_dir):\n",
    "    if root_dir and os.path.isdir(root_dir):\n",
    "        p = os.path.join(root_dir, \"_background_noise_\")\n",
    "        if os.path.isdir(p):\n",
    "            return p\n",
    "    kaggle_noise = \"/kaggle/input/speech-commands/_background_noise_\"\n",
    "    return kaggle_noise if os.path.isdir(kaggle_noise) else None\n",
    "\n",
    "NOISE_DIR = resolve_noise_dir(ROOT_DIR)\n",
    "\n",
    "if not COMMIT_MODE and VERBOSE_CONFIG:\n",
    "    print(\"Data root:\", ROOT_DIR if ROOT_DIR else \"<not found>\")\n",
    "    print(\"Noise dir:\", NOISE_DIR if NOISE_DIR else \"<not found>\")\n",
    "\n",
    "SELECTED_CLASSES = [\"down\", \"left\", \"right\", \"up\"]\n",
    "CLASS_TO_IDX = {c: i for i, c in enumerate(SELECTED_CLASSES)}\n",
    "\n",
    "MAX_LENGTH = SR  \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "N_SPLITS = 5\n",
    "SEEDS = [36, 38, 42]\n",
    "\n",
    "NOISE_PROB = 0.30\n",
    "SNR_RANGE = (5, 20)\n",
    "\n",
    "NUM_WORKERS = max(2, (os.cpu_count() or 2) // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c3042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:37:48.288417Z",
     "iopub.status.busy": "2026-01-06T13:37:48.287886Z",
     "iopub.status.idle": "2026-01-06T13:37:48.302045Z",
     "shell.execute_reply": "2026-01-06T13:37:48.301305Z"
    },
    "papermill": {
     "duration": 0.019061,
     "end_time": "2026-01-06T13:37:48.303118",
     "exception": false,
     "start_time": "2026-01-06T13:37:48.284057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resolve_noise_path(noise_dir: str, filename: str):\n",
    "    if not noise_dir or not filename:\n",
    "        return None\n",
    "    p = os.path.join(noise_dir, filename)\n",
    "    return p if os.path.exists(p) else None\n",
    "    \n",
    "WHITE_PATH = resolve_noise_path(NOISE_DIR, WHITE_NOISE_FILE)\n",
    "PINK_PATH  = resolve_noise_path(NOISE_DIR, PINK_NOISE_FILE)\n",
    "\n",
    "try:\n",
    "    _color = str(NOISE_COLOR).lower()\n",
    "except Exception:\n",
    "    _color = 'white'\n",
    "if _color == 'pink' and PINK_PATH:\n",
    "    cand_path = PINK_PATH; cand_name = 'pink'\n",
    "else:\n",
    "    cand_path = WHITE_PATH; cand_name = 'white'\n",
    "if not cand_path or not os.path.exists(cand_path):\n",
    "    ACTIVE_NOISE_PATH = None\n",
    "    ACTIVE_NOISE_NAME = f\"{cand_name} (missing)\"\n",
    "else:\n",
    "    ACTIVE_NOISE_PATH = cand_path\n",
    "    ACTIVE_NOISE_NAME = cand_name\n",
    "\n",
    "_NOISE_CACHE = {}\n",
    "\n",
    "def _load_and_prepare_noise(noise_path: str, target_sr: int):\n",
    "    noise, sr = torchaudio.load(noise_path)\n",
    "    if noise.dim() == 1:\n",
    "        noise = noise.unsqueeze(0)\n",
    "    if noise.shape[0] > 1:\n",
    "        noise = noise.mean(dim=0, keepdim=True)\n",
    "    if sr != target_sr:\n",
    "        noise = torchaudio.functional.resample(noise, sr, target_sr)\n",
    "    noise = noise.to(dtype=torch.float32, device='cpu')\n",
    "    noise = noise - noise.mean()\n",
    "    return noise\n",
    "\n",
    "def _get_noise_cached(noise_path: str, target_sr: int):\n",
    "    if (noise_path is None) or (not os.path.exists(noise_path)):\n",
    "        return None\n",
    "    key = (noise_path, int(target_sr))\n",
    "    if key not in _NOISE_CACHE:\n",
    "        _NOISE_CACHE[key] = _load_and_prepare_noise(noise_path, target_sr)\n",
    "    return _NOISE_CACHE[key]\n",
    "\n",
    "def _take_random_segment(noise_cpu: torch.Tensor, T: int):\n",
    "    N = noise_cpu.shape[1]\n",
    "    if N >= T:\n",
    "        start = int(torch.randint(0, max(1, N - T + 1), (1,)).item()) if N > T else 0\n",
    "        return noise_cpu[:, start:start+T]\n",
    "    rep = math.ceil(T / N)\n",
    "    tiled = noise_cpu.repeat(1, rep)\n",
    "    return tiled[:, :T]\n",
    "\n",
    "def add_specific_noise(\n",
    "    waveform: torch.Tensor,\n",
    "    noise_path: str,\n",
    "    snr_db: float,\n",
    "    target_sr: int\n",
    "):\n",
    "    noise_cpu = _get_noise_cached(noise_path, target_sr)\n",
    "    if noise_cpu is None:\n",
    "        return waveform\n",
    "    T = waveform.shape[1]\n",
    "    seg = _take_random_segment(noise_cpu, T)\n",
    "    noise = seg.to(device=waveform.device, dtype=waveform.dtype)\n",
    "    sig_power   = waveform.pow(2).mean().clamp(min=1e-12)\n",
    "    noise_power = noise.pow(2).mean().clamp(min=1e-12)\n",
    "    snr_linear  = 10.0 ** (snr_db / 10.0)\n",
    "    scale = torch.sqrt(sig_power / (snr_linear * noise_power))\n",
    "    noisy = waveform + scale * noise\n",
    "    return torch.clamp(noisy, -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefeac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:37:48.309411Z",
     "iopub.status.busy": "2026-01-06T13:37:48.309209Z",
     "iopub.status.idle": "2026-01-06T13:37:48.319390Z",
     "shell.execute_reply": "2026-01-06T13:37:48.318706Z"
    },
    "papermill": {
     "duration": 0.014762,
     "end_time": "2026-01-06T13:37:48.320563",
     "exception": false,
     "start_time": "2026-01-06T13:37:48.305801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VoiceCommandDatasetWithNoise(Dataset):\n",
    "    def __init__(self,\n",
    "                 samples, class_to_idx,\n",
    "                 noise_path=None, is_training=True,\n",
    "                 sr=SR, max_length=None,\n",
    "                 n_mfcc=N_MFCC, n_fft=400, hop_length=160, n_mels=None,\n",
    "                 augment=\"file_noise\", noise_prob=0.0,\n",
    "                 snr_range=(5,20), fixed_snr_db=None,\n",
    "                 norm_mode=\"none\", global_mean=None, global_std=None,\n",
    "                 crop_mode=\"left\", return_path=False, seed=None):\n",
    "        super().__init__()\n",
    "        self.samples, self.class_to_idx = samples, class_to_idx\n",
    "        self.noise_path, self.is_training = noise_path, bool(is_training)\n",
    "        self.sr = int(sr)\n",
    "        self.max_length = int(max_length if max_length is not None else sr)\n",
    "\n",
    "        self.augment      = str(augment)   \n",
    "        self.noise_prob   = float(noise_prob)\n",
    "        self.snr_range    = snr_range\n",
    "        self.fixed_snr_db = fixed_snr_db\n",
    "        self.norm_mode    = str(norm_mode)\n",
    "        self.global_mean  = (torch.tensor(global_mean, dtype=torch.float32)\n",
    "                             if global_mean is not None else None)\n",
    "        self.global_std   = (torch.tensor(global_std, dtype=torch.float32)\n",
    "                             if global_std is not None else None)\n",
    "        self.crop_mode    = str(crop_mode)\n",
    "        self.return_path  = bool(return_path)\n",
    "        self._rng = random.Random(seed) if seed is not None else random\n",
    "\n",
    "        if self.is_training and self.augment == \"file_noise\":\n",
    "            if not self.noise_path or not os.path.exists(self.noise_path):\n",
    "                raise FileNotFoundError(f\"noise_path tidak valid: {self.noise_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _crop(self, x_2d):\n",
    "        T = x_2d.shape[1]\n",
    "        if T < self.max_length:\n",
    "            return F.pad(x_2d, (0, self.max_length - T))\n",
    "        if T > self.max_length:\n",
    "            start = 0 if self.crop_mode == \"left\" else max(0, (T - self.max_length)//2)\n",
    "            return x_2d[:, start:start+self.max_length]\n",
    "        return x_2d\n",
    "\n",
    "    def _maybe_augment(self, x_2d):\n",
    "        if not (self.is_training and self.augment != \"none\"):\n",
    "            return x_2d\n",
    "        if self._rng.random() >= self.noise_prob:\n",
    "            return x_2d\n",
    "\n",
    "        snr_db = float(self.fixed_snr_db) if self.fixed_snr_db is not None \\\n",
    "                 else self._rng.uniform(*self.snr_range)\n",
    "\n",
    "        if self.augment == \"file_noise\" and self.noise_path:\n",
    "            return add_specific_noise(x_2d, self.noise_path, snr_db, target_sr=self.sr)\n",
    "\n",
    "        return x_2d\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        path, cname = self.samples[idx]\n",
    "        y = int(self.class_to_idx[cname])\n",
    "\n",
    "        x_2d, sr0 = torchaudio.load(path)\n",
    "        if x_2d.dim() == 1:\n",
    "            x_2d = x_2d.unsqueeze(0)\n",
    "        if x_2d.shape[0] > 1:\n",
    "            x_2d = x_2d.mean(0, keepdim=True)\n",
    "\n",
    "        if sr0 != self.sr:\n",
    "            x_2d = torchaudio.functional.resample(x_2d, sr0, self.sr)\n",
    "\n",
    "        x_2d = self._crop(x_2d).to(torch.float32)\n",
    "        x_2d = self._maybe_augment(x_2d)\n",
    "\n",
    "        x_1d = x_2d.squeeze(0).contiguous()\n",
    "        return (x_1d, torch.tensor(y, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366ce8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:37:48.327439Z",
     "iopub.status.busy": "2026-01-06T13:37:48.327007Z",
     "iopub.status.idle": "2026-01-06T13:38:00.929657Z",
     "shell.execute_reply": "2026-01-06T13:38:00.928793Z"
    },
    "papermill": {
     "duration": 12.607655,
     "end_time": "2026-01-06T13:38:00.930936",
     "exception": false,
     "start_time": "2026-01-06T13:37:48.323281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "def collect_samples_4classes(root_dir: str, selected_classes, exts=(\".wav\", \".WAV\")):\n",
    "    samples = []\n",
    "    if not root_dir or not Path(root_dir).is_dir():\n",
    "        return samples\n",
    "    root = Path(root_dir)\n",
    "\n",
    "    for cname in selected_classes:\n",
    "        cdir = root / cname\n",
    "        if not cdir.is_dir():\n",
    "            continue\n",
    "        for ent in cdir.iterdir():\n",
    "            if ent.is_file() and ent.suffix.lower() == \".wav\":\n",
    "                samples.append((str(ent), cname))\n",
    "    samples.sort(key=lambda x: x[0])\n",
    "    return samples\n",
    "\n",
    "all_samples = collect_samples_4classes(ROOT_DIR, SELECTED_CLASSES)\n",
    "\n",
    "if VERBOSE_CONFIG:\n",
    "    per_class = Counter([c for _, c in all_samples])\n",
    "    print(f\"[DATASET] classes={len(SELECTED_CLASSES)} samples={len(all_samples)} per_class={dict(per_class)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6caf965",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:38:00.938111Z",
     "iopub.status.busy": "2026-01-06T13:38:00.937414Z",
     "iopub.status.idle": "2026-01-06T13:38:00.943243Z",
     "shell.execute_reply": "2026-01-06T13:38:00.942561Z"
    },
    "papermill": {
     "duration": 0.010407,
     "end_time": "2026-01-06T13:38:00.944305",
     "exception": false,
     "start_time": "2026-01-06T13:38:00.933898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'VERBOSE_CONFIG' in globals() and VERBOSE_CONFIG:\n",
    "    mfcc_all = {int(sr): mfcc_params_for_sr(int(sr)) for sr in SR_LIST}\n",
    "    lines = [\"[CONFIG]\",\n",
    "             f\"ARCH={ARCH}\",\n",
    "             f\"Device={device}\",\n",
    "             f\"SR_LIST={SR_LIST}\",\n",
    "             \"MFCC params per SR:\"]\n",
    "    for _sr, v in sorted(mfcc_all.items()):\n",
    "        lines.append(f\"  SR={_sr}: n_fft={v['n_fft']} win={v['win_length']} hop={v['hop_length']}\")\n",
    "    lines.extend([\n",
    "        f\"Classes={len(SELECTED_CLASSES)} Samples={len(all_samples)}\",\n",
    "        f\"Noise color={ACTIVE_NOISE_NAME} path={ACTIVE_NOISE_PATH if ACTIVE_NOISE_PATH else 'None'}\",\n",
    "        f\"Noise prob={NOISE_PROB} SNR_RANGE={SNR_RANGE}\",\n",
    "        f\"Batch size={BATCH_SIZE} Epochs={EPOCHS} KFold={N_SPLITS} Seeds={SEEDS}\"])\n",
    "    print(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb04124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:38:00.950884Z",
     "iopub.status.busy": "2026-01-06T13:38:00.950662Z",
     "iopub.status.idle": "2026-01-06T13:38:00.963843Z",
     "shell.execute_reply": "2026-01-06T13:38:00.963246Z"
    },
    "papermill": {
     "duration": 0.017768,
     "end_time": "2026-01-06T13:38:00.964827",
     "exception": false,
     "start_time": "2026-01-06T13:38:00.947059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os              \n",
    "import torch           \n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    WHITE_PATH\n",
    "except NameError:\n",
    "    WHITE_PATH = resolve_noise_path(NOISE_DIR, WHITE_NOISE_FILE) if 'NOISE_DIR' in globals() and 'WHITE_NOISE_FILE' in globals() else None\n",
    "\n",
    "def build_kfold_loaders_generic(\n",
    "    samples, class_to_idx,\n",
    "    sr=None, n_splits=5, seed=42,\n",
    "    batch_size=64, num_workers=2, pin_memory=True,\n",
    "    noise_path=None,\n",
    "    max_length=None,\n",
    "    noise_prob=0.0, snr_range=(5,20),\n",
    "    augment_mode=\"file_noise\",\n",
    "    norm_mode=\"none\",\n",
    "    crop_mode=\"left\"\n",
    "):\n",
    "    sr = int(sr if sr is not None else globals().get(\"SR\", 16000))\n",
    "    max_length = int(max_length if max_length is not None else sr)\n",
    "\n",
    "    if not samples or len(samples) == 0:\n",
    "        if 'VERBOSE_CONFIG' in globals() and VERBOSE_CONFIG and not globals().get('COMMIT_MODE', False):\n",
    "            print(f\"[WARN] No samples found for sr={sr}. Skipping KFold construction.\")\n",
    "        return []\n",
    "\n",
    "    params = mfcc_params_for_sr(sr)\n",
    "    n_fft_rule      = params[\"n_fft\"]\n",
    "    win_length_rule = params[\"win_length\"]\n",
    "    hop_length_rule = params[\"hop_length\"]\n",
    "\n",
    "    y_all = np.array([class_to_idx[c] for _, c in samples], dtype=np.int64)\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=int(seed))\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    pm = bool(pin_memory and use_cuda)\n",
    "    dl_args = dict(\n",
    "        batch_size=int(batch_size),\n",
    "        num_workers=int(num_workers),\n",
    "        pin_memory=pm,\n",
    "        persistent_workers=True if int(num_workers) > 0 else False,\n",
    "        prefetch_factor=4 if int(num_workers) > 0 else None,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    if dl_args[\"prefetch_factor\"] is None:\n",
    "        dl_args.pop(\"prefetch_factor\")\n",
    "\n",
    "    use_file_noise = (augment_mode == \"file_noise\")\n",
    "    effective_noise_path = noise_path\n",
    "    if use_file_noise and (effective_noise_path is None or not os.path.exists(effective_noise_path)):\n",
    "        if 'VERBOSE_CONFIG' in globals() and VERBOSE_CONFIG and not globals().get('COMMIT_MODE', False):\n",
    "            print(\"[NOISE] Missing or invalid noise_path -> disabling file_noise augmentation.\")\n",
    "        use_file_noise = False\n",
    "        effective_noise_path = None\n",
    "        noise_prob = 0.0\n",
    "\n",
    "    g_base = int(seed) * 1_000_003\n",
    "    folds = []\n",
    "\n",
    "    for fold_id, (tr_idx, va_idx) in enumerate(skf.split(samples, y_all), start=1):\n",
    "        tr_s = [samples[i] for i in tr_idx]\n",
    "        va_s = [samples[i] for i in va_idx]\n",
    "\n",
    "        ds_tr = VoiceCommandDatasetWithNoise(\n",
    "            tr_s, class_to_idx,\n",
    "            noise_path=(effective_noise_path if use_file_noise else None),\n",
    "            is_training=True,\n",
    "            sr=sr, max_length=max_length,\n",
    "            n_mfcc=N_MFCC, n_fft=n_fft_rule, hop_length=hop_length_rule, n_mels=N_MELS,\n",
    "            augment=(\"file_noise\" if use_file_noise else \"none\"), noise_prob=noise_prob, snr_range=snr_range,\n",
    "            norm_mode=norm_mode, crop_mode=crop_mode,\n",
    "            return_path=False, seed=g_base + fold_id\n",
    "        )\n",
    "        ds_va = VoiceCommandDatasetWithNoise(\n",
    "            va_s, class_to_idx,\n",
    "            noise_path=None, is_training=False,\n",
    "            sr=sr, max_length=max_length,\n",
    "            n_mfcc=N_MFCC, n_fft=n_fft_rule, hop_length=hop_length_rule, n_mels=N_MELS,\n",
    "            augment=\"none\", noise_prob=0.0, snr_range=snr_range,\n",
    "            norm_mode=norm_mode, crop_mode=crop_mode,\n",
    "            return_path=False, seed=g_base + 10_000 + fold_id\n",
    "        )\n",
    "\n",
    "        g = torch.Generator(device=\"cpu\"); g.manual_seed(g_base + fold_id)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, shuffle=True,  generator=g, **dl_args)\n",
    "        dl_va = DataLoader(ds_va, shuffle=False,                 **dl_args)\n",
    "\n",
    "        if not COMMIT_MODE and ('VERBOSE_CONFIG' in globals() and VERBOSE_CONFIG):\n",
    "            aug_str = (\"file_noise\" if use_file_noise else \"none\")\n",
    "            print(f\"[SR={sr} | seed={seed} | fold={fold_id}] \"\n",
    "                  f\"train={len(tr_s)} val={len(va_s)} | n_fft={n_fft_rule} win={win_length_rule} hop={hop_length_rule} \"\n",
    "                  f\"(workers={num_workers}, pin_memory={pm}) | augment={aug_str}\")\n",
    "\n",
    "        folds.append({\"fold\": fold_id, \"train_loader\": dl_tr, \"val_loader\": dl_va})\n",
    "\n",
    "    return folds\n",
    "\n",
    "\n",
    "def build_kfold_loaders_noise(\n",
    "    samples, class_to_idx, n_splits=5, seed=42,\n",
    "    batch_size=64, num_workers=2, pin_memory=True,\n",
    "    noise_path=None, max_length=None,\n",
    "    noise_prob=NOISE_PROB, snr_range=SNR_RANGE, sr=None\n",
    "):\n",
    "    return build_kfold_loaders_generic(\n",
    "        samples=samples, class_to_idx=class_to_idx,\n",
    "        sr=sr, n_splits=n_splits, seed=seed,\n",
    "        batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory,\n",
    "        noise_path=(noise_path if noise_path is not None else ACTIVE_NOISE_PATH),\n",
    "        max_length=max_length,\n",
    "        noise_prob=noise_prob, snr_range=snr_range,\n",
    "        augment_mode=\"file_noise\",\n",
    "        norm_mode=\"none\", crop_mode=\"left\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f37376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:38:00.971159Z",
     "iopub.status.busy": "2026-01-06T13:38:00.970974Z",
     "iopub.status.idle": "2026-01-06T13:38:00.980252Z",
     "shell.execute_reply": "2026-01-06T13:38:00.979848Z"
    },
    "papermill": {
     "duration": 0.013752,
     "end_time": "2026-01-06T13:38:00.981344",
     "exception": false,
     "start_time": "2026-01-06T13:38:00.967592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 4096, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model, dtype=torch.float32)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) *\n",
    "                             (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0), persistent=False)  \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        T = x.size(1)\n",
    "        pe = self.pe[:, :T, :].to(dtype=x.dtype, device=x.device)\n",
    "        return self.dropout(x + pe)\n",
    "\n",
    "class MFCC_Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_mfcc: int = N_MFCC,\n",
    "        num_classes: int | None = None,\n",
    "        d_model: int = 128,\n",
    "        nhead: int = 4,\n",
    "        num_layers: int = 2,\n",
    "        dim_feedforward: int = 256,\n",
    "        dropout: float = 0.3,\n",
    "        max_len: int = 4096,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if num_classes is None:\n",
    "            num_classes = len(SELECTED_CLASSES)\n",
    "\n",
    "        assert d_model % nhead == 0, \"d_model harus kelipatan nhead\"\n",
    "        self.n_mfcc = int(n_mfcc)\n",
    "\n",
    "        self.input_proj = nn.Linear(self.n_mfcc, d_model, bias=True)\n",
    "        self.posenc = PositionalEncoding(d_model, max_len=max_len, dropout=0.0)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout, activation=\"gelu\", batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, num_classes),\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.dim() != 3:\n",
    "            raise ValueError(f\"Expected 3D input [B,T,{self.n_mfcc}] or [B,{self.n_mfcc},T], got {tuple(x.shape)}\")\n",
    "        B, A, C = x.shape\n",
    "        if C == self.n_mfcc:\n",
    "            pass\n",
    "        elif A == self.n_mfcc:\n",
    "            x = x.transpose(1, 2).contiguous()\n",
    "        else:\n",
    "            raise ValueError(f\"Input last dim must be n_mfcc={self.n_mfcc}; got {tuple(x.shape)}\")\n",
    "\n",
    "        h = self.input_proj(x)     \n",
    "        h = self.posenc(h)          \n",
    "        h = self.encoder(h)         \n",
    "        feat = h.mean(dim=1)        \n",
    "        logits = self.head(feat)    \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60b68be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:38:00.987460Z",
     "iopub.status.busy": "2026-01-06T13:38:00.987282Z",
     "iopub.status.idle": "2026-01-06T13:38:00.997813Z",
     "shell.execute_reply": "2026-01-06T13:38:00.997231Z"
    },
    "papermill": {
     "duration": 0.014811,
     "end_time": "2026-01-06T13:38:00.998839",
     "exception": false,
     "start_time": "2026-01-06T13:38:00.984028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import nullcontext\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "_mfcc_cfg = mfcc_params_for_sr(SR)  \n",
    "WIN_LENGTH = _mfcc_cfg[\"win_length\"]\n",
    "HOP_LENGTH = _mfcc_cfg[\"hop_length\"]\n",
    "N_FFT      = _mfcc_cfg[\"n_fft\"]\n",
    "\n",
    "mfcc = None  \n",
    "\n",
    "def _compute_feats_gpu(wav: torch.Tensor) -> torch.Tensor:\n",
    "    if mfcc is None:\n",
    "        raise RuntimeError(\"MFCC transform not initialized yet; run the training loop cell after defining SR-specific mfcc\")\n",
    "    feats = mfcc(wav)\n",
    "    feats = feats.transpose(1, 2).contiguous()\n",
    "    return feats\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, scheduler=None, grad_clip_norm=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    use_amp = (\"SCALER\" in globals()) and (SCALER is not None) and (device.type == \"cuda\")\n",
    "    amp_ctx = (torch.autocast(device_type=\"cuda\", dtype=AMP_DTYPE) if use_amp else nullcontext())\n",
    "\n",
    "    step_per_batch = (\n",
    "        scheduler is not None\n",
    "        and not isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau)\n",
    "    )\n",
    "\n",
    "    for wav, y in loader:\n",
    "        wav = wav.to(device, non_blocking=NON_BLOCK).float()\n",
    "        y   = y.to(device, non_blocking=NON_BLOCK).long()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with amp_ctx:\n",
    "            feats  = _compute_feats_gpu(wav)\n",
    "            logits = model(feats)\n",
    "            loss   = criterion(logits, y)\n",
    "\n",
    "        if use_amp:\n",
    "            SCALER.scale(loss).backward()\n",
    "            if grad_clip_norm is not None:\n",
    "                SCALER.unscale_(optimizer)\n",
    "                clip_grad_norm_(model.parameters(), max_norm=float(grad_clip_norm))\n",
    "            SCALER.step(optimizer)\n",
    "            SCALER.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            if grad_clip_norm is not None:\n",
    "                clip_grad_norm_(model.parameters(), max_norm=float(grad_clip_norm))\n",
    "            optimizer.step()\n",
    "\n",
    "        if step_per_batch:\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "\n",
    "    return float(total_loss) / float(len(loader.dataset))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion=None):\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    total_loss = 0.0\n",
    "    have_loss = criterion is not None\n",
    "\n",
    "    use_amp = (device.type == \"cuda\")\n",
    "    amp_ctx = (torch.autocast(device_type=\"cuda\", dtype=AMP_DTYPE) if use_amp else nullcontext())\n",
    "\n",
    "    for wav, y in loader:\n",
    "        wav = wav.to(device, non_blocking=NON_BLOCK).float()\n",
    "        y   = y.to(device, non_blocking=NON_BLOCK).long()\n",
    "\n",
    "        with amp_ctx:\n",
    "            feats  = _compute_feats_gpu(wav)\n",
    "            logits = model(feats)\n",
    "            if have_loss:\n",
    "                total_loss += criterion(logits, y).item() * y.size(0)\n",
    "\n",
    "        pred = logits.argmax(dim=1)\n",
    "        all_true.extend(y.tolist())\n",
    "        all_pred.extend(pred.tolist())\n",
    "\n",
    "    acc = accuracy_score(all_true, all_pred)\n",
    "    f1  = f1_score(all_true, all_pred, average=\"macro\")\n",
    "    avg_loss = (float(total_loss) / float(len(loader.dataset))) if have_loss else None\n",
    "\n",
    "    return float(acc), float(f1), avg_loss, np.array(all_true, dtype=np.int64), np.array(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d76dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:38:01.005098Z",
     "iopub.status.busy": "2026-01-06T13:38:01.004741Z",
     "iopub.status.idle": "2026-01-06T13:38:02.477406Z",
     "shell.execute_reply": "2026-01-06T13:38:02.476812Z"
    },
    "papermill": {
     "duration": 1.477304,
     "end_time": "2026-01-06T13:38:02.478833",
     "exception": false,
     "start_time": "2026-01-06T13:38:01.001529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "COMMIT_MODE = True\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "\n",
    "    if COMMIT_MODE:\n",
    "        kwargs[\"disable\"] = True\n",
    "    return _tqdm(*args, **kwargs)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "pd.set_option(\"display.max_colwidth\", 120)\n",
    "\n",
    "if COMMIT_MODE:\n",
    "    def _no_show(*args, **kwargs):\n",
    "        pass\n",
    "    plt.show = _no_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb6819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:38:02.486121Z",
     "iopub.status.busy": "2026-01-06T13:38:02.485774Z",
     "iopub.status.idle": "2026-01-06T14:55:24.782049Z",
     "shell.execute_reply": "2026-01-06T14:55:24.780896Z"
    },
    "papermill": {
     "duration": 4642.302424,
     "end_time": "2026-01-06T14:55:24.784297",
     "exception": false,
     "start_time": "2026-01-06T13:38:02.481873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io, sys, contextlib, os, time, numpy as np, pandas as pd, shutil, json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SR_LIST = sorted(set(int(s) for s in SR_LIST))\n",
    "\n",
    "def _outdirs_for(SR: int):\n",
    "    root = Path(f\"/kaggle/working/kfold_outputs_sr{SR}\")\n",
    "    d_fold = root / \"per_seed_and_fold\"\n",
    "    d_sum  = root / \"summary\"\n",
    "    d_fold.mkdir(parents=True, exist_ok=True)\n",
    "    d_sum.mkdir(parents=True, exist_ok=True)\n",
    "    return root, d_fold, d_sum\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def mute_outputs(active: bool):\n",
    "    if not active:\n",
    "        yield\n",
    "    else:\n",
    "        buf = io.StringIO()\n",
    "        with contextlib.redirect_stdout(buf), contextlib.redirect_stderr(buf):\n",
    "            yield\n",
    "\n",
    "USE_CUDA   = torch.cuda.is_available()\n",
    "AMP_ENABLE = USE_CUDA\n",
    "if AMP_ENABLE:\n",
    "    try:\n",
    "        major_cc = torch.cuda.get_device_capability()[0]\n",
    "    except Exception:\n",
    "        major_cc = 7\n",
    "    AMP_DTYPE = torch.bfloat16 if major_cc >= 8 else torch.float16\n",
    "    try:\n",
    "        SCALER = torch.amp.GradScaler(device=\"cuda\") if AMP_DTYPE is torch.float16 else None\n",
    "    except Exception:\n",
    "        SCALER = torch.cuda.amp.GradScaler(enabled=(AMP_DTYPE is torch.float16))\n",
    "else:\n",
    "    AMP_DTYPE = None\n",
    "    SCALER = None\n",
    "\n",
    "results = []\n",
    "summary_rows = []\n",
    "efficiency_rows_global = []\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "with mute_outputs(COMMIT_MODE):\n",
    "    for seed in SEEDS:\n",
    "        if not COMMIT_MODE and VERBOSE_CONFIG:\n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(f\"Running SEED = {seed} | ARCH = {ARCH}\")\n",
    "            print(\"=\"*70)\n",
    "        set_seed(seed)\n",
    "\n",
    "        for sr in SR_LIST:\n",
    "            SR = int(sr)\n",
    "            ROOT_OUT, OUT_FOLD, OUT_SUMM = _outdirs_for(SR)\n",
    "            MAX_LENGTH = SR\n",
    "\n",
    "            folds = build_kfold_loaders_noise(\n",
    "                all_samples, CLASS_TO_IDX,\n",
    "                n_splits=N_SPLITS, seed=seed,\n",
    "                batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
    "                noise_path=ACTIVE_NOISE_PATH,\n",
    "                max_length=MAX_LENGTH, noise_prob=NOISE_PROB, snr_range=SNR_RANGE,\n",
    "                sr=SR\n",
    "            )\n",
    "\n",
    "            # MFCC transform per SR\n",
    "            _params = mfcc_params_for_sr(SR)\n",
    "            if not COMMIT_MODE and VERBOSE_CONFIG:\n",
    "                print(f\"[MFCC] SR={SR} -> n_fft={_params['n_fft']} win_length={_params['win_length']} hop_length={_params['hop_length']} n_mels={N_MELS}\")\n",
    "            mfcc = torchaudio.transforms.MFCC(\n",
    "                sample_rate=SR, n_mfcc=N_MFCC,\n",
    "                melkwargs={\n",
    "                    \"n_mels\": N_MELS,\n",
    "                    \"n_fft\": int(_params[\"n_fft\"]),\n",
    "                    \"hop_length\": int(_params[\"hop_length\"]),\n",
    "                    \"win_length\": int(_params[\"win_length\"]),\n",
    "                    \"center\": True, \"f_min\": 0.0, \"f_max\": SR/2\n",
    "                }\n",
    "            ).to(device)\n",
    "\n",
    "            def _compute_feats_gpu(wav: torch.Tensor) -> torch.Tensor:\n",
    "                return mfcc(wav).transpose(1, 2).contiguous()\n",
    "\n",
    "            for fd in folds:\n",
    "                fold_id      = fd[\"fold\"]\n",
    "                train_loader = fd[\"train_loader\"]\n",
    "                val_loader   = fd[\"val_loader\"]\n",
    "\n",
    "                RUN_NAME = f\"{ARCH}_seed{seed}_fold{fold_id}_sr{SR}\"\n",
    "                OUT_SUB  = str((ROOT_OUT / \"per_seed_and_fold\" / RUN_NAME).resolve())\n",
    "                os.makedirs(OUT_SUB, exist_ok=True)\n",
    "                BEST_CKPT = os.path.join(OUT_SUB, \"best_model.pth\")\n",
    "                LAST_CKPT = os.path.join(OUT_SUB, \"last_model.pth\")\n",
    "\n",
    "                model = MFCC_Transformer(n_mfcc=N_MFCC, num_classes=len(SELECTED_CLASSES)).to(device)\n",
    "                assert next(model.parameters()).is_cuda == USE_CUDA, \"Model belum di CUDA!\"\n",
    "                n_params = int(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "                optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "                total_steps = max(1, EPOCHS * len(train_loader))\n",
    "                scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                    optimizer, max_lr=1e-3, total_steps=total_steps\n",
    "                )\n",
    "                criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "                best_val_acc = -1.0\n",
    "                best_true = best_pred = None\n",
    "\n",
    "                history = []\n",
    "\n",
    "                for ep in range(1, EPOCHS+1):\n",
    "                    model.train()\n",
    "                    tr_loss_sum, n_train = 0.0, 0\n",
    "                    ep_t0 = time.time()\n",
    "\n",
    "                    for wav, y in train_loader:\n",
    "                        wav = wav.to(device, non_blocking=NON_BLOCK).float()\n",
    "                        y   = y.to(device,  non_blocking=NON_BLOCK).long()\n",
    "                        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                        if AMP_ENABLE:\n",
    "                            with torch.autocast(device_type='cuda', dtype=AMP_DTYPE):\n",
    "                                feats  = _compute_feats_gpu(wav)\n",
    "                                logits = model(feats)\n",
    "                                loss   = criterion(logits, y)\n",
    "                            if SCALER is not None:\n",
    "                                SCALER.scale(loss).backward()\n",
    "                                SCALER.step(optimizer)\n",
    "                                SCALER.update()\n",
    "                            else:\n",
    "                                loss.backward()\n",
    "                                optimizer.step()\n",
    "                        else:\n",
    "                            feats  = _compute_feats_gpu(wav)\n",
    "                            logits = model(feats)\n",
    "                            loss   = criterion(logits, y)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                        if scheduler is not None:\n",
    "                            scheduler.step()\n",
    "                        bs = y.size(0)\n",
    "                        tr_loss_sum += loss.item() * bs\n",
    "                        n_train += bs\n",
    "\n",
    "                    tr_loss = tr_loss_sum / max(1, n_train)\n",
    "\n",
    "                    val_acc, val_f1, val_loss, y_true, y_pred = evaluate(model, val_loader, criterion)\n",
    "\n",
    "                    if val_acc > best_val_acc:\n",
    "                        best_val_acc = float(val_acc)\n",
    "                        best_true = y_true.copy()\n",
    "                        best_pred = y_pred.copy()\n",
    "                        torch.save(model.state_dict(), BEST_CKPT)\n",
    "\n",
    "                    ep_time = time.time() - ep_t0\n",
    "                    thr = float(n_train) / ep_time if ep_time > 0 else 0.0\n",
    "                    history.append({\n",
    "                        \"epoch\": ep,\n",
    "                        \"train_loss\": float(tr_loss),\n",
    "                        \"val_loss\": float(val_loss),\n",
    "                        \"val_acc\": float(val_acc),\n",
    "                        \"val_f1\": float(val_f1),\n",
    "                        \"epoch_time_sec\": float(ep_time),\n",
    "                        \"throughput_samples_per_sec\": float(thr),\n",
    "                    })\n",
    "\n",
    "                    if (ep % 5 == 0 or ep == 1 or ep == EPOCHS) and not COMMIT_MODE:\n",
    "                        if USE_CUDA:\n",
    "                            gpu_mb = torch.cuda.memory_allocated() / 1e6\n",
    "                            print(f\"[SR={SR} | GPU {gpu_mb:.1f} MB]\", end=\" \")\n",
    "                        print(f\"Seed {seed} | Fold {fold_id} | Epoch {ep:02d} \"\n",
    "                              f\"| tr_loss={tr_loss:.4f} | va_loss={val_loss:.4f} \"\n",
    "                              f\"| va_acc={val_acc:.4f} | va_f1={val_f1:.4f} | ep_time={ep_time:.2f}s | thr={thr:.1f}/s\")\n",
    "\n",
    "                torch.save(model.state_dict(), LAST_CKPT)\n",
    "\n",
    "                # Confusion matrix and history saving\n",
    "                cm = confusion_matrix(best_true, best_pred, labels=list(range(len(SELECTED_CLASSES))))\n",
    "                cm_df = pd.DataFrame(cm, index=SELECTED_CLASSES, columns=SELECTED_CLASSES)\n",
    "                cm_path = os.path.join(OUT_FOLD, f\"cm_{ARCH}_seed{seed}_fold{fold_id}_sr{SR}.csv\")\n",
    "                cm_df.to_csv(cm_path)\n",
    "\n",
    "                hist_df = pd.DataFrame(history)\n",
    "                hist_df.to_csv(os.path.join(OUT_SUB, \"history.csv\"), index=False)\n",
    "\n",
    "                # Efficiency row for optional later aggregation\n",
    "                total_time = float(hist_df[\"epoch_time_sec\"].sum()) if not hist_df.empty else 0.0\n",
    "                avg_ep_time = float(hist_df[\"epoch_time_sec\"].mean()) if not hist_df.empty else 0.0\n",
    "                mean_thr = float(hist_df[\"throughput_samples_per_sec\"].mean()) if not hist_df.empty else 0.0\n",
    "                efficiency_rows_global.append({\n",
    "                    \"sr\": SR,\n",
    "                    \"seed\": seed,\n",
    "                    \"fold\": fold_id,\n",
    "                    \"arch\": ARCH,\n",
    "                    \"n_params\": n_params,\n",
    "                    \"epochs\": EPOCHS,\n",
    "                    \"total_time_sec\": total_time,\n",
    "                    \"avg_epoch_time_sec\": avg_ep_time,\n",
    "                    \"mean_throughput_samples_per_sec\": mean_thr,\n",
    "                })\n",
    "\n",
    "                results.append({\n",
    "                    \"seed\": seed,\n",
    "                    \"fold\": fold_id,\n",
    "                    \"sr\": int(SR),\n",
    "                    \"val_acc\": float(best_val_acc),\n",
    "                    \"cm_path\": cm_path,\n",
    "                    \"ckpt_path\": BEST_CKPT,\n",
    "                })\n",
    "\n",
    "        # Aggregate per-seed summaries\n",
    "        for sr0 in SR_LIST:\n",
    "            accs = [r[\"val_acc\"] for r in results if r[\"seed\"] == seed and r[\"sr\"] == int(sr0)]\n",
    "            if accs:\n",
    "                summary_rows.append({\n",
    "                    \"seed\": seed,\n",
    "                    \"sr\": int(sr0),\n",
    "                    \"acc_mean_over_folds\": float(np.mean(accs)),\n",
    "                    \"acc_std_over_folds\":  float(np.std(accs)),\n",
    "                    \"n_folds\": N_SPLITS\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7e276",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T14:55:24.792834Z",
     "iopub.status.busy": "2026-01-06T14:55:24.792579Z",
     "iopub.status.idle": "2026-01-06T14:55:24.847875Z",
     "shell.execute_reply": "2026-01-06T14:55:24.847219Z"
    },
    "papermill": {
     "duration": 0.061414,
     "end_time": "2026-01-06T14:55:24.849301",
     "exception": false,
     "start_time": "2026-01-06T14:55:24.787887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_results_all = pd.DataFrame(results)\n",
    "df_seed_all    = pd.DataFrame(summary_rows)\n",
    "\n",
    "for SR in SR_LIST:\n",
    "    ROOT_OUT, OUT_FOLD, OUT_SUMM = _outdirs_for(SR)\n",
    "\n",
    "    if not df_results_all.empty:\n",
    "        df_res_sr = df_results_all[df_results_all[\"sr\"] == int(SR)].copy()\n",
    "        if len(df_res_sr):\n",
    "            df_res_sr.to_csv(OUT_FOLD / f\"transformer_kfold_results_per_fold_sr{SR}.csv\", index=False)\n",
    "\n",
    "    if not df_seed_all.empty:\n",
    "        df_seed_sr = df_seed_all[df_seed_all[\"sr\"] == int(SR)].copy()\n",
    "        if len(df_seed_sr):\n",
    "            df_seed_sr.to_csv(OUT_SUMM / f\"transformer_kfold_summary_per_seed_sr{SR}.csv\", index=False)\n",
    "\n",
    "            mu_acc = float(df_seed_sr[\"acc_mean_over_folds\"].mean())\n",
    "            sd_acc = float(df_seed_sr[\"acc_mean_over_folds\"].std(ddof=1)) if len(df_seed_sr) > 1 else 0.0\n",
    "\n",
    "            df_sr_summary = pd.DataFrame([{\n",
    "                \"model\": \"Transformer\",\n",
    "                \"sr\": int(SR),\n",
    "                \"acc_mean\": mu_acc,\n",
    "                \"acc_sd\": sd_acc,\n",
    "                \"n_seeds\": int(df_seed_sr[\"seed\"].nunique()),\n",
    "                \"kfold\": int(df_seed_sr[\"n_folds\"].max()) if \"n_folds\" in df_seed_sr else 5\n",
    "            }])\n",
    "            df_sr_summary.to_csv(OUT_SUMM / f\"transformer_kfold_multi_seed_summary_sr{SR}.csv\", index=False)\n",
    "\n",
    "    df_res_sr = df_results_all[df_results_all[\"sr\"] == int(SR)].copy()\n",
    "    if not df_res_sr.empty:\n",
    "        manifest_path = OUT_SUMM / f\"transformer_best_checkpoints_per_seed_fold_sr{SR}.csv\"\n",
    "        cols = [\"seed\", \"fold\", \"sr\", \"val_acc\", \"ckpt_path\", \"cm_path\"]\n",
    "        (df_res_sr[cols].sort_values([\"seed\", \"fold\"]).to_csv(manifest_path, index=False))\n",
    "\n",
    "        idx_per_seed = df_res_sr.groupby(\"seed\")[\"val_acc\"].idxmax()\n",
    "        df_best_per_seed = df_res_sr.loc[idx_per_seed].copy().sort_values([\"seed\"]).reset_index(drop=True)\n",
    "\n",
    "        per_seed_csv = OUT_SUMM / f\"transformer_best_per_seed_sr{SR}.csv\"\n",
    "        df_best_per_seed[[\"seed\", \"fold\", \"sr\", \"val_acc\", \"ckpt_path\"]].to_csv(per_seed_csv, index=False)\n",
    "\n",
    "        for _, row in df_best_per_seed.iterrows():\n",
    "            src = Path(row[\"ckpt_path\"])\n",
    "            dst = OUT_SUMM / f\"bestmodel_seed{int(row['seed'])}_sr{int(SR)}.pth\"\n",
    "            try:\n",
    "                dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy2(src, dst)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN][SR={SR}] Gagal salin best per seed {int(row['seed'])}: {e}\")\n",
    "\n",
    "        row_sr_best = df_res_sr.loc[df_res_sr[\"val_acc\"].idxmax()]\n",
    "        src = Path(row_sr_best[\"ckpt_path\"])\n",
    "        dst = ROOT_OUT / f\"bestmodel_sr{int(SR)}.pth\"\n",
    "        try:\n",
    "            dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(src, dst)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN][SR={SR}] Gagal salin best per SR: {e}\")\n",
    "\n",
    "if not df_results_all.empty:\n",
    "    row_global = df_results_all.loc[df_results_all[\"val_acc\"].idxmax()]\n",
    "    src = Path(row_global[\"ckpt_path\"])\n",
    "    final_dst = Path(\"/kaggle/working\") / \"bestmodel.pth\"\n",
    "    try:\n",
    "        final_dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(src, final_dst)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Gagal salin global best: {e}\")\n",
    "\n",
    "legacy_dir = \"/kaggle/working/kfold_outputs\"\n",
    "os.makedirs(legacy_dir, exist_ok=True)\n",
    "\n",
    "all_best_rows = []\n",
    "\n",
    "for SR in SR_LIST:\n",
    "    ROOT_OUT, OUT_FOLD, OUT_SUMM = _outdirs_for(SR)\n",
    "    df_res_sr = df_results_all[df_results_all[\"sr\"] == int(SR)].copy()\n",
    "    if df_res_sr.empty:\n",
    "        continue\n",
    "\n",
    "    idx_per_seed = df_res_sr.groupby(\"seed\")[\"val_acc\"].idxmax()\n",
    "    df_best_per_seed = df_res_sr.loc[idx_per_seed].copy().sort_values([\"seed\"]).reset_index(drop=True)\n",
    "\n",
    "    best_rows_sr = []\n",
    "    for _, rec in df_best_per_seed.iterrows():\n",
    "        slim = {\n",
    "            \"seed\": int(rec[\"seed\"]),\n",
    "            \"fold\": int(rec[\"fold\"]),\n",
    "            \"sr\":   int(rec[\"sr\"]),\n",
    "            \"val_acc\": float(rec[\"val_acc\"]),\n",
    "            \"cm_path\": rec.get(\"cm_path\", None),\n",
    "            \"ckpt_path\": rec.get(\"ckpt_path\", None),\n",
    "        }\n",
    "        best_rows_sr.append(slim)\n",
    "        with open(OUT_SUMM / f\"transformer_best_seed{slim['seed']}_fold{slim['fold']}_sr{SR}.json\", \"w\") as f:\n",
    "            json.dump(slim, f, indent=2)\n",
    "\n",
    "    pd.DataFrame(best_rows_sr).to_csv(OUT_SUMM / f\"transformer_best_per_seed_sr{SR}.csv\", index=False)\n",
    "    with open(OUT_SUMM / f\"transformer_best_per_seed_sr{SR}.json\", \"w\") as f:\n",
    "        json.dump(best_rows_sr, f, indent=2)\n",
    "\n",
    "    all_best_rows.extend(best_rows_sr)\n",
    "\n",
    "if all_best_rows:\n",
    "    df_best_all = pd.DataFrame(all_best_rows).sort_values([\"sr\", \"seed\"]).reset_index(drop=True)\n",
    "    df_best_path_csv  = os.path.join(legacy_dir, \"transformer_best_per_seed.csv\")\n",
    "    df_best_path_json = os.path.join(legacy_dir, \"transformer_best_per_seed.json\")\n",
    "    df_best_all.to_csv(df_best_path_csv, index=False)\n",
    "    with open(df_best_path_json, \"w\") as f:\n",
    "        json.dump(all_best_rows, f, indent=2)\n",
    "\n",
    "if not COMMIT_MODE:\n",
    "    for SR in SR_LIST:\n",
    "        ROOT_OUT, OUT_FOLD, OUT_SUMM = _outdirs_for(SR)\n",
    "        print(f\"\\n[SR={SR}] Saved to:\")\n",
    "        print(f\"  {OUT_FOLD}/transformer_kfold_results_per_fold_sr{SR}.csv\")\n",
    "        print(f\"  {OUT_SUMM}/transformer_kfold_summary_per_seed_sr{SR}.csv\")\n",
    "        print(f\"  {OUT_SUMM}/transformer_kfold_multi_seed_summary_sr{SR}.csv\")\n",
    "        print(f\"  {OUT_SUMM}/transformer_best_checkpoints_per_seed_fold_sr{SR}.csv\")\n",
    "        print(f\"  {OUT_SUMM}/transformer_best_per_seed_sr{SR}.csv\")\n",
    "        print(f\"  {OUT_SUMM}/transformer_speed_efficiency_per_fold_sr{SR}.csv\")\n",
    "        print(f\"  {OUT_SUMM}/transformer_speed_efficiency_per_seed_sr{SR}.csv\")\n",
    "        print(f\"  {OUT_SUMM}/transformer_best_per_seed_sr{SR}.json\")\n",
    "        print(f\"  {ROOT_OUT}/bestmodel_sr{SR}.pth\")\n",
    "        print(f\"  /kaggle/working/bestmodel.pth (global, opsional)\")\n",
    "        print(f\"  /kaggle/working/kfold_outputs/transformer_best_per_seed.csv|json (legacy)\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6666857,
     "sourceId": 10749559,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4668.416055,
   "end_time": "2026-01-06T14:55:27.474794",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-06T13:37:39.058739",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
