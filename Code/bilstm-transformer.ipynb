{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c49699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T00:44:55.860774Z",
     "iopub.status.busy": "2026-01-06T00:44:55.860536Z",
     "iopub.status.idle": "2026-01-06T00:44:55.866605Z",
     "shell.execute_reply": "2026-01-06T00:44:55.866064Z"
    },
    "papermill": {
     "duration": 0.011659,
     "end_time": "2026-01-06T00:44:55.867591",
     "exception": false,
     "start_time": "2026-01-06T00:44:55.855932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if 'VERBOSE_CONFIG' not in globals():\n",
    "    VERBOSE_CONFIG = True\n",
    "\n",
    "if 'NOISE_COLOR' not in globals():\n",
    "    NOISE_COLOR = os.getenv('NOISE_COLOR', 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386b76c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T00:44:55.874923Z",
     "iopub.status.busy": "2026-01-06T00:44:55.874724Z",
     "iopub.status.idle": "2026-01-06T00:44:59.400429Z",
     "shell.execute_reply": "2026-01-06T00:44:59.399508Z"
    },
    "papermill": {
     "duration": 3.530934,
     "end_time": "2026-01-06T00:44:59.401923",
     "exception": false,
     "start_time": "2026-01-06T00:44:55.870989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as _np\n",
    "import torch as _torch\n",
    "import librosa as _librosa\n",
    "\n",
    "_NOISE_CACHE = {}\n",
    "\n",
    "def _load_noise_1d(path: str, sr: int):\n",
    "    key = (str(path), int(sr))\n",
    "    arr = _NOISE_CACHE.get(key, None)\n",
    "    if arr is None:\n",
    "        wav, _ = _librosa.load(path, sr=sr, mono=True)\n",
    "        if wav.size == 0:\n",
    "            wav = _np.zeros(1, dtype=_np.float32)\n",
    "        arr = wav.astype(_np.float32).copy()\n",
    "        _NOISE_CACHE[key] = arr\n",
    "    return arr\n",
    "\n",
    "def _to_tensor(x):\n",
    "    if _torch.is_tensor(x):\n",
    "        return x.float(), \"torch\"\n",
    "    if isinstance(x, _np.ndarray):\n",
    "        return _torch.from_numpy(x.copy()).float(), \"numpy\"\n",
    "    try:\n",
    "        return _torch.tensor(x).float(), \"other\"\n",
    "    except Exception:\n",
    "        raise TypeError(f\"Unsupported type for add_specific_noise: {type(x)}\")\n",
    "\n",
    "def _to_output(x_tensor, kind):\n",
    "    if kind == \"torch\":\n",
    "        return x_tensor\n",
    "    if kind in (\"numpy\", \"other\"):\n",
    "        return x_tensor.detach().cpu().numpy()\n",
    "    return x_tensor\n",
    "\n",
    "def _pick_segment_torch(noise_tensor: _torch.Tensor, length: int, gen: _torch.Generator | None = None):\n",
    "    n = int(noise_tensor.numel())\n",
    "    if n == 0:\n",
    "        return _torch.zeros(length, dtype=_torch.float32)\n",
    "    if n >= length:\n",
    "        max_start = n - length\n",
    "        start = int(_torch.randint(low=0, high=max_start+1, size=(1,), generator=gen).item())\n",
    "    reps = (length + n - 1) // n\n",
    "    tiled = noise_tensor.repeat(reps)[:length]\n",
    "    return tiled.clone()\n",
    "\n",
    "def _mix_to_snr_torch(clean: _torch.Tensor, noise: _torch.Tensor, snr_db: float):\n",
    "    eps = 1e-12\n",
    "    clean64 = clean.double()\n",
    "    noise64 = noise.double()\n",
    "    p_clean = _torch.sum(clean64**2) + eps\n",
    "    p_noise = _torch.sum(noise64**2) + eps\n",
    "    target_ratio = 10.0 ** (-float(snr_db) / 10.0)\n",
    "    alpha = _torch.sqrt(_torch.tensor(target_ratio, dtype=_torch.float64) * p_clean / p_noise)\n",
    "    mixed = clean64 + alpha * noise64\n",
    "    return mixed.float()\n",
    "\n",
    "def add_specific_noise(x, noise_path: str, snr_db: float, target_sr: int = None, rng=None):\n",
    "    \"\"\"\n",
    "    Add file-based noise at a given SNR.\n",
    "    - If x is 1D (waveform) or 2D (features), supports both torch.Tensor and numpy.ndarray.\n",
    "    - 1D: time-domain mixing using file noise.\n",
    "    - 2D: feature-domain fallback using Gaussian noise calibrated to target SNR.\n",
    "    \"\"\"\n",
    "    x_t, kind = _to_tensor(x)\n",
    "\n",
    "    if x_t.ndim == 1:\n",
    "        assert target_sr is not None, \"target_sr must be set for 1D waveform augmentation\"\n",
    "        noise_np = _load_noise_1d(noise_path, target_sr)\n",
    "        noise_t = _torch.from_numpy(noise_np).float()\n",
    "        seg = _pick_segment_torch(noise_t, x_t.numel())\n",
    "        out = _mix_to_snr_torch(x_t.view(-1), seg.view(-1), float(snr_db))\n",
    "        return _to_output(out.view_as(x_t), kind)\n",
    "\n",
    "    if x_t.ndim == 2:\n",
    "        clean = x_t\n",
    "        eps = 1e-12\n",
    "        clean64 = clean.double()\n",
    "        p_clean = _torch.sum(clean64**2) + eps\n",
    "        g = _torch.randn_like(clean)\n",
    "        p_g = _torch.sum(g.double()**2) + eps\n",
    "        target_ratio = 10.0 ** (-float(snr_db) / 10.0)\n",
    "        alpha = _torch.sqrt(_torch.tensor(target_ratio, dtype=_torch.float64) * p_clean / p_g)\n",
    "        out = (clean64 + alpha * g.double()).float()\n",
    "        return _to_output(out, kind)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc1d47",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-06T00:44:59.409608Z",
     "iopub.status.busy": "2026-01-06T00:44:59.409101Z",
     "iopub.status.idle": "2026-01-06T00:44:59.424343Z",
     "shell.execute_reply": "2026-01-06T00:44:59.423663Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.020291,
     "end_time": "2026-01-06T00:44:59.425537",
     "exception": false,
     "start_time": "2026-01-06T00:44:59.405246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = Path(globals().get(\"DATA_ROOT\", \"/kaggle/input/speech-commands\"))\n",
    "NOISE_ROOT = Path(globals().get(\"NOISE_ROOT\", \"/kaggle/input/speech-commands/_background_noise_\"))\n",
    "WORK_ROOT  = Path(globals().get(\"WORK_ROOT\", \"/kaggle/working\"))\n",
    "OUTPUT_ROOT = Path(globals().get(\"OUTPUT_ROOT\", WORK_ROOT / \"outputs\"))\n",
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def resolve_noise_path(root=NOISE_ROOT, name=\"white\"):\n",
    "    name = str(name).lower()\n",
    "    candidates = {\n",
    "        \"white\": [\"white_noise.wav\",\"white.wav\",\"white-noise.wav\"],\n",
    "        \"pink\":  [\"pink_noise.wav\",\"pink.wav\",\"pink-noise.wav\"],\n",
    "    }\n",
    "    files = candidates.get(name, [])\n",
    "    for fn in files:\n",
    "        p = Path(root) / fn\n",
    "        if p.exists():\n",
    "            return p.as_posix()\n",
    "    try:\n",
    "        for p in Path(root).glob(\"*.wav\"):\n",
    "            if name in p.name.lower():\n",
    "                return p.as_posix()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return (Path(root) / (files[0] if files else \"\")).as_posix()\n",
    "\n",
    "WHITE_PATH = resolve_noise_path(NOISE_ROOT, \"white\")\n",
    "PINK_PATH  = resolve_noise_path(NOISE_ROOT, \"pink\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d445d27",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-06T00:44:59.432890Z",
     "iopub.status.busy": "2026-01-06T00:44:59.432260Z",
     "iopub.status.idle": "2026-01-06T00:45:01.419532Z",
     "shell.execute_reply": "2026-01-06T00:45:01.418887Z"
    },
    "papermill": {
     "duration": 1.99218,
     "end_time": "2026-01-06T00:45:01.420907",
     "exception": false,
     "start_time": "2026-01-06T00:44:59.428727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, random, math, time, json\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "if \"COMMIT_MODE\" not in globals():\n",
    "    COMMIT_MODE = False\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42, deterministic: bool = True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = bool(deterministic)\n",
    "    torch.backends.cudnn.benchmark = not bool(deterministic)\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "PIN_MEMORY = True if USE_CUDA else False\n",
    "NON_BLOCK = True if USE_CUDA else False\n",
    "\n",
    "SR_LIST = sorted(set(int(s) for s in (globals().get(\"SR_LIST\", [16000]))))\n",
    "SR = SR_LIST[-1]\n",
    "MAX_LENGTH = SR\n",
    "\n",
    "\n",
    "def mfcc_params_for_sr(sr: int) -> dict:\n",
    "    sr = int(sr)\n",
    "    if sr == 16000:\n",
    "        return {\"win_length\": 400, \"hop_length\": 160, \"n_fft\": 512}\n",
    "    if sr == 8000:\n",
    "        return {\"win_length\": 200, \"hop_length\": 80, \"n_fft\": 256}\n",
    "    win_length = int(round(sr * 0.025))\n",
    "    hop_length = int(round(sr * 0.010))\n",
    "    n_fft = 1\n",
    "    while n_fft < win_length:\n",
    "        n_fft <<= 1\n",
    "    return {\"win_length\": win_length, \"hop_length\": hop_length, \"n_fft\": n_fft}\n",
    "\n",
    "_rule = mfcc_params_for_sr(SR)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "N_SPLITS = 5\n",
    "SEEDS = [36, 38, 42]\n",
    "\n",
    "ARCH = \"bilstm_transformer\"\n",
    "\n",
    "LSTM_HIDDEN  = 128\n",
    "LSTM_LAYERS  = 2\n",
    "LSTM_DROPOUT = 0.2\n",
    "\n",
    "NOISE_PROB = 0.30\n",
    "SNR_RANGE = (5, 20)\n",
    "\n",
    "NUM_WORKERS = max(2, (os.cpu_count() or 2) // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c389429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T00:45:01.428335Z",
     "iopub.status.busy": "2026-01-06T00:45:01.428030Z",
     "iopub.status.idle": "2026-01-06T00:45:11.751225Z",
     "shell.execute_reply": "2026-01-06T00:45:11.750231Z"
    },
    "papermill": {
     "duration": 10.328275,
     "end_time": "2026-01-06T00:45:11.752516",
     "exception": false,
     "start_time": "2026-01-06T00:45:01.424241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, pandas as pd, json, hashlib\n",
    "\n",
    "WANTED_CLASSES = [\"up\",\"down\",\"left\",\"right\"]\n",
    "ALLOWED_EXTS = (\".wav\",)\n",
    "\n",
    "root = Path(DATA_ROOT)\n",
    "assert root.exists(), f\"DATA_ROOT tidak ditemukan: {root}\"\n",
    "\n",
    "FORCE_RESCAN = False\n",
    "VERBOSE = True\n",
    "\n",
    "manifests_dir = Path(OUTPUT_ROOT) / \"manifests\"\n",
    "manifests_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sig = hashlib.md5(json.dumps({\n",
    "    \"root\": str(root.resolve()),\n",
    "    \"wanted\": sorted(WANTED_CLASSES),\n",
    "    \"exts\": list(ALLOWED_EXTS),\n",
    "}, sort_keys=True).encode()).hexdigest()\n",
    "MANIFEST_CSV = manifests_dir / f\"manifest_subset_{sig}.csv\"\n",
    "\n",
    "def _log_manifest(action: str, counts):\n",
    "    if VERBOSE and VERBOSE_CONFIG:\n",
    "        print(f\"[MANIFEST] {action}: total={int(counts.sum())} per_class={dict(counts)}\")\n",
    "\n",
    "def scan_subset_one_level():\n",
    "    missing = [c for c in WANTED_CLASSES if not (root / c).is_dir()]\n",
    "    assert not missing, f\"Folder kelas tidak ditemukan: {missing}\"\n",
    "    rows = []\n",
    "    for cls in sorted(WANTED_CLASSES):\n",
    "        d = root / cls\n",
    "        for ent in os.scandir(d):\n",
    "            if ent.is_file() and ent.name.lower().endswith(ALLOWED_EXTS):\n",
    "                rows.append((str(Path(ent.path)), cls))\n",
    "    assert rows, f\"Tidak ada file {ALLOWED_EXTS} untuk subset kelas {WANTED_CLASSES} di {root}\"\n",
    "    return pd.DataFrame(rows, columns=[\"path\",\"label\"])\n",
    "\n",
    "reuse_ok = False\n",
    "if (not FORCE_RESCAN) and (\"all_samples\" in globals()) and isinstance(all_samples, list) and all_samples:\n",
    "    _df_in = pd.DataFrame(all_samples, columns=[\"path\",\"label\"])\n",
    "    cur_classes = sorted(_df_in[\"label\"].unique().tolist())\n",
    "    if sorted(WANTED_CLASSES) == cur_classes:\n",
    "        _df = _df_in.copy()\n",
    "        reuse_ok = True\n",
    "        counts = _df[\"label\"].value_counts().sort_index()\n",
    "        _log_manifest(\"reuse in-memory\", counts)\n",
    "\n",
    "if (not reuse_ok) and (not FORCE_RESCAN) and MANIFEST_CSV.exists():\n",
    "    _df = pd.read_csv(MANIFEST_CSV)\n",
    "    cur_classes = sorted(_df[\"label\"].unique().tolist())\n",
    "    if sorted(WANTED_CLASSES) == cur_classes:\n",
    "        counts = _df[\"label\"].value_counts().sort_index()\n",
    "        _log_manifest(\"reuse manifest\", counts)\n",
    "    else:\n",
    "        _df = scan_subset_one_level()\n",
    "        _df.to_csv(MANIFEST_CSV, index=False)\n",
    "        counts = _df[\"label\"].value_counts().sort_index()\n",
    "        _log_manifest(\"refresh manifest\", counts)\n",
    "\n",
    "if 'all_samples' not in globals() or not reuse_ok:\n",
    "    if '_df' not in locals():\n",
    "        _df = scan_subset_one_level()\n",
    "        _df.to_csv(MANIFEST_CSV, index=False)\n",
    "        counts = _df[\"label\"].value_counts().sort_index()\n",
    "        _log_manifest(\"scan subset\", counts)\n",
    "\n",
    "all_samples = list(map(tuple, _df[[\"path\",\"label\"]].itertuples(index=False, name=None)))\n",
    "SELECTED_CLASSES = sorted(WANTED_CLASSES)\n",
    "CLASS_TO_IDX = {c:i for i,c in enumerate(SELECTED_CLASSES)}\n",
    "\n",
    "if VERBOSE_CONFIG:\n",
    "    print(f\"[DATASET] classes={len(SELECTED_CLASSES)} samples={len(all_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a12cb8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T00:45:11.760224Z",
     "iopub.status.busy": "2026-01-06T00:45:11.759692Z",
     "iopub.status.idle": "2026-01-06T00:45:11.771893Z",
     "shell.execute_reply": "2026-01-06T00:45:11.771311Z"
    },
    "papermill": {
     "duration": 0.017124,
     "end_time": "2026-01-06T00:45:11.772971",
     "exception": false,
     "start_time": "2026-01-06T00:45:11.755847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "NOISE_PATH  = globals().get(\"NOISE_PATH\", globals().get(\"WHITE_PATH\", None))\n",
    "NOISE_PROB  = globals().get(\"NOISE_PROB\", 0.0)\n",
    "SNR_RANGE   = globals().get(\"SNR_RANGE\", (5, 20))\n",
    "COMMIT_MODE = globals().get(\"COMMIT_MODE\", False)\n",
    "N_MFCC      = globals().get(\"N_MFCC\", 40)\n",
    "N_MELS      = globals().get(\"N_MELS\", 40)\n",
    "\n",
    "\n",
    "def build_kfold_loaders_generic(\n",
    "    samples, class_to_idx,\n",
    "    sr=None, n_splits=5, seed=42,\n",
    "    batch_size=64, num_workers=2, pin_memory=True,\n",
    "    noise_path=None,\n",
    "    max_length=None,\n",
    "    noise_prob=None, snr_range=None,\n",
    "    augment_mode=\"file_noise\",\n",
    "    norm_mode=\"none\",\n",
    "    crop_mode=\"left\"\n",
    "):\n",
    "    sr = int(sr if sr is not None else globals().get(\"SR\", 16000))\n",
    "    max_length = int(max_length if max_length is not None else sr)\n",
    "    if noise_prob is None: noise_prob = NOISE_PROB\n",
    "    if snr_range is None:  snr_range  = SNR_RANGE\n",
    "\n",
    "    params = mfcc_params_for_sr(sr)\n",
    "    n_fft_rule      = params[\"n_fft\"]\n",
    "    win_length_rule = params[\"win_length\"]\n",
    "    hop_length_rule = params[\"hop_length\"]\n",
    "\n",
    "    effective_noise_path = noise_path if noise_path is not None else NOISE_PATH\n",
    "    use_file_noise = (augment_mode == \"file_noise\")\n",
    "    if use_file_noise and (effective_noise_path is None or not os.path.exists(effective_noise_path)):\n",
    "        raise FileNotFoundError(\n",
    "            f\"[ERROR] Noise file tidak ditemukan!\\n\"\n",
    "            f\"  - noise_path: {effective_noise_path}\\n\"\n",
    "            f\"  - NOISE_COLOR: {globals().get('NOISE_COLOR', 'unknown')}\\n\"\n",
    "        )\n",
    "\n",
    "    y_all = np.array([class_to_idx[c] for _, c in samples], dtype=np.int64)\n",
    "    skf = StratifiedKFold(n_splits=int(n_splits), shuffle=True, random_state=int(seed))\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    pm = bool(pin_memory and use_cuda)\n",
    "\n",
    "    dl_args = dict(\n",
    "        batch_size=int(batch_size),\n",
    "        num_workers=int(num_workers),\n",
    "        pin_memory=pm,\n",
    "        persistent_workers=True if int(num_workers) > 0 else False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    if int(num_workers) > 0:\n",
    "        dl_args['prefetch_factor'] = 4\n",
    "\n",
    "    g_base = int(seed) * 1_000_003\n",
    "    folds = []\n",
    "\n",
    "    for fold_id, (tr_idx, va_idx) in enumerate(skf.split(samples, y_all), start=1):\n",
    "        tr_s = [samples[i] for i in tr_idx]\n",
    "        va_s = [samples[i] for i in va_idx]\n",
    "\n",
    "        ds_tr = VoiceCommandDatasetWithNoise(\n",
    "            tr_s, class_to_idx,\n",
    "            noise_path=(effective_noise_path if use_file_noise else None),\n",
    "            is_training=True,\n",
    "            sr=sr, max_length=max_length,\n",
    "            n_mfcc=N_MFCC, n_fft=n_fft_rule, hop_length=hop_length_rule, n_mels=N_MELS,\n",
    "            augment=(\"file_noise\" if use_file_noise else \"none\"),\n",
    "            noise_prob=noise_prob, snr_range=snr_range,\n",
    "            norm_mode=norm_mode, crop_mode=crop_mode,\n",
    "            return_path=False, seed=g_base + fold_id\n",
    "        )\n",
    "        ds_va = VoiceCommandDatasetWithNoise(\n",
    "            va_s, class_to_idx,\n",
    "            noise_path=None, is_training=False,\n",
    "            sr=sr, max_length=max_length,\n",
    "            n_mfcc=N_MFCC, n_fft=n_fft_rule, hop_length=hop_length_rule, n_mels=N_MELS,\n",
    "            augment=\"none\", noise_prob=0.0, snr_range=snr_range,\n",
    "            norm_mode=norm_mode, crop_mode=crop_mode,\n",
    "            return_path=False, seed=g_base + 10_000 + fold_id\n",
    "        )\n",
    "\n",
    "        g = torch.Generator(device=\"cpu\"); g.manual_seed(g_base + fold_id)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, shuffle=True,  generator=g, **dl_args)\n",
    "        dl_va = DataLoader(ds_va, shuffle=False,                 **dl_args)\n",
    "\n",
    "        if not COMMIT_MODE and VERBOSE_CONFIG:\n",
    "            aug_str = (\"file_noise\" if use_file_noise else \"none\")\n",
    "            print(f\"[SR={sr} | seed={seed} | fold={fold_id}] train={len(tr_s)} val={len(va_s)}\"\\\n",
    "                  f\" | n_fft={n_fft_rule} win={win_length_rule} hop={hop_length_rule} (workers={num_workers}, pin_memory={pm})\"\\\n",
    "                  f\" | augment={aug_str}\")\n",
    "\n",
    "        folds.append({\"fold\": fold_id, \"train_loader\": dl_tr, \"val_loader\": dl_va})\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd535a8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T00:45:11.779680Z",
     "iopub.status.busy": "2026-01-06T00:45:11.779399Z",
     "iopub.status.idle": "2026-01-06T00:45:11.783945Z",
     "shell.execute_reply": "2026-01-06T00:45:11.783421Z"
    },
    "papermill": {
     "duration": 0.009017,
     "end_time": "2026-01-06T00:45:11.784962",
     "exception": false,
     "start_time": "2026-01-06T00:45:11.775945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose active noise file based on NOISE_COLOR (white/pink) and expose NOISE_PATH for downstream\n",
    "try:\n",
    "    color = str(NOISE_COLOR).lower()\n",
    "except Exception:\n",
    "    color = \"white\"\n",
    "\n",
    "if color == \"pink\" and 'PINK_PATH' in globals():\n",
    "    _candidate = PINK_PATH\n",
    "    _name = \"pink\"\n",
    "else:\n",
    "    _candidate = WHITE_PATH if 'WHITE_PATH' in globals() else None\n",
    "    _name = \"white\"\n",
    "\n",
    "if not _candidate or not os.path.exists(_candidate):\n",
    "    ACTIVE_NOISE_PATH = None\n",
    "    ACTIVE_NOISE_NAME = f\"{_name} (missing)\"\n",
    "else:\n",
    "    ACTIVE_NOISE_PATH = _candidate\n",
    "    ACTIVE_NOISE_NAME = _name\n",
    "\n",
    "globals()[\"NOISE_PATH\"] = ACTIVE_NOISE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fd52a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T00:45:11.791960Z",
     "iopub.status.busy": "2026-01-06T00:45:11.791753Z",
     "iopub.status.idle": "2026-01-06T00:45:11.796729Z",
     "shell.execute_reply": "2026-01-06T00:45:11.796058Z"
    },
    "papermill": {
     "duration": 0.009685,
     "end_time": "2026-01-06T00:45:11.797732",
     "exception": false,
     "start_time": "2026-01-06T00:45:11.788047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if VERBOSE_CONFIG:\n",
    "    mfcc_all = {sr: mfcc_params_for_sr(int(sr)) for sr in SR_LIST}\n",
    "    lines = [\"[CONFIG]\",\n",
    "             f\"ARCH={ARCH}\",\n",
    "             f\"Device={device}\",\n",
    "             f\"SR_LIST={SR_LIST}\",\n",
    "             \"MFCC params per SR:\" ]\n",
    "    for sr,val in mfcc_all.items():\n",
    "        lines.append(f\"  SR={sr}: n_fft={val['n_fft']} win={val['win_length']} hop={val['hop_length']}\")\n",
    "    lines.extend([\n",
    "        f\"Classes={len(SELECTED_CLASSES)} Samples={len(all_samples)}\",\n",
    "        f\"Noise color={ACTIVE_NOISE_NAME} path={ACTIVE_NOISE_PATH if ACTIVE_NOISE_PATH else 'None'}\",\n",
    "        f\"Noise prob={NOISE_PROB} SNR_RANGE={SNR_RANGE}\",\n",
    "        f\"Batch size={BATCH_SIZE} Epochs={EPOCHS} KFold={N_SPLITS} Seeds={SEEDS}\",\n",
    "        f\"LSTM hidden={LSTM_HIDDEN} layers={LSTM_LAYERS} dropout={LSTM_DROPOUT}\"])\n",
    "    print(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f324a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T00:45:11.804823Z",
     "iopub.status.busy": "2026-01-06T00:45:11.804623Z",
     "iopub.status.idle": "2026-01-06T00:45:11.814928Z",
     "shell.execute_reply": "2026-01-06T00:45:11.814246Z"
    },
    "papermill": {
     "duration": 0.015177,
     "end_time": "2026-01-06T00:45:11.816040",
     "exception": false,
     "start_time": "2026-01-06T00:45:11.800863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VoiceCommandDatasetWithNoise(Dataset):\n",
    "    def __init__(self,\n",
    "                 samples, class_to_idx,\n",
    "                 noise_path=None, is_training=True,\n",
    "                 sr=SR, max_length=None,\n",
    "                 n_mfcc=N_MFCC, n_fft=400, hop_length=160, n_mels=None,\n",
    "                 augment=\"file_noise\", noise_prob=0.0,\n",
    "                 snr_range=(5,20), fixed_snr_db=None,\n",
    "                 norm_mode=\"none\", global_mean=None, global_std=None,\n",
    "                 crop_mode=\"left\", return_path=False, seed=None):\n",
    "        super().__init__()\n",
    "        self.samples, self.class_to_idx = samples, class_to_idx\n",
    "        self.noise_path, self.is_training = noise_path, bool(is_training)\n",
    "        self.sr = int(sr)\n",
    "        self.max_length = int(max_length if max_length is not None else sr)\n",
    "\n",
    "        self.augment      = str(augment)\n",
    "        self.noise_prob   = float(noise_prob)\n",
    "        self.snr_range    = snr_range\n",
    "        self.fixed_snr_db = fixed_snr_db\n",
    "        self.norm_mode    = str(norm_mode)\n",
    "        self.global_mean  = (torch.tensor(global_mean, dtype=torch.float32)\n",
    "                             if global_mean is not None else None)\n",
    "        self.global_std   = (torch.tensor(global_std, dtype=torch.float32)\n",
    "                             if global_std is not None else None)\n",
    "        self.crop_mode    = str(crop_mode)\n",
    "        self.return_path  = bool(return_path)\n",
    "        self._rng = random.Random(seed) if seed is not None else random\n",
    "\n",
    "        if self.is_training and self.augment == \"file_noise\":\n",
    "            if not self.noise_path or not os.path.exists(self.noise_path):\n",
    "                raise FileNotFoundError(f\"noise_path tidak valid: {self.noise_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _crop(self, x_2d):\n",
    "        T = x_2d.shape[1]\n",
    "        if T < self.max_length:\n",
    "            return F.pad(x_2d, (0, self.max_length - T))\n",
    "        if T > self.max_length:\n",
    "            start = 0 if self.crop_mode == \"left\" else max(0, (T - self.max_length)//2)\n",
    "            return x_2d[:, start:start+self.max_length]\n",
    "        return x_2d\n",
    "\n",
    "    def _maybe_augment(self, x_2d):\n",
    "        if not (self.is_training and self.augment != \"none\"):\n",
    "            return x_2d\n",
    "        if self._rng.random() >= self.noise_prob:\n",
    "            return x_2d\n",
    "\n",
    "        snr_db = float(self.fixed_snr_db) if self.fixed_snr_db is not None \\\n",
    "                 else self._rng.uniform(*self.snr_range)\n",
    "\n",
    "        if self.augment == \"file_noise\" and self.noise_path:\n",
    "            x_1d = x_2d.squeeze(0)  # [1, T] -> [T]\n",
    "            x_aug = add_specific_noise(x_1d, self.noise_path, snr_db, target_sr=self.sr)\n",
    "            return x_aug.unsqueeze(0)  # [T] -> [1, T]\n",
    "\n",
    "        return x_2d\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        path, cname = self.samples[idx]\n",
    "        y = int(self.class_to_idx[cname])\n",
    "\n",
    "        x_2d, sr0 = torchaudio.load(path)\n",
    "        if x_2d.dim() == 1:\n",
    "            x_2d = x_2d.unsqueeze(0)\n",
    "        if x_2d.shape[0] > 1:\n",
    "            x_2d = x_2d.mean(0, keepdim=True)\n",
    "\n",
    "        if sr0 != self.sr:\n",
    "            x_2d = torchaudio.functional.resample(x_2d, sr0, self.sr)\n",
    "\n",
    "        x_2d = self._crop(x_2d).to(torch.float32)\n",
    "        x_2d = self._maybe_augment(x_2d)\n",
    "\n",
    "        x_1d = x_2d.squeeze(0).contiguous()\n",
    "        return (x_1d, torch.tensor(y, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf55b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T00:45:11.824016Z",
     "iopub.status.busy": "2026-01-06T00:45:11.823819Z",
     "iopub.status.idle": "2026-01-06T00:45:11.839058Z",
     "shell.execute_reply": "2026-01-06T00:45:11.838363Z"
    },
    "papermill": {
     "duration": 0.020129,
     "end_time": "2026-01-06T00:45:11.840205",
     "exception": false,
     "start_time": "2026-01-06T00:45:11.820076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 4096, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, d_model, dtype=torch.float32)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) *\n",
    "                             (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0), persistent=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B,T,d_model]\n",
    "        T = x.size(1)\n",
    "        pe = self.pe[:, :T, :].to(dtype=x.dtype, device=x.device)\n",
    "        return self.dropout(x + pe)\n",
    "\n",
    "class MFCC_Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_mfcc: int,\n",
    "                 num_classes: int,\n",
    "                 d_model: int = 128,\n",
    "                 nhead: int = 4,\n",
    "                 num_layers: int = 2,\n",
    "                 dim_feedforward: int = 256,\n",
    "                 dropout: float = 0.3,\n",
    "                 max_len: int = 4096):\n",
    "        super().__init__()\n",
    "        self.n_mfcc = int(n_mfcc)\n",
    "        self.input_proj = nn.Linear(self.n_mfcc, d_model)\n",
    "        self.posenc  = PositionalEncoding(d_model=d_model, max_len=max_len, dropout=dropout)\n",
    "        enc_layer    = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n",
    "                                                  dim_feedforward=dim_feedforward,\n",
    "                                                  dropout=dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B,T,n_mfcc] / [B,n_mfcc,T]\n",
    "        if x.dim() != 3:\n",
    "            raise ValueError(f\"Expected 3D input, got {tuple(x.shape)}\")\n",
    "        if x.shape[-1] == self.n_mfcc:\n",
    "            seq = x                                 # [B,T,F]\n",
    "        elif x.shape[1] == self.n_mfcc:\n",
    "            seq = x.transpose(1, 2).contiguous()    # [B,T,F]\n",
    "        else:\n",
    "            raise ValueError(f\"Input last dim must be n_mfcc={self.n_mfcc}; got {tuple(x.shape)}\")\n",
    "        h = self.input_proj(seq)\n",
    "        h = self.posenc(h)\n",
    "        h = self.encoder(h)\n",
    "        feat = h.mean(dim=1)\n",
    "        return self.head(feat)\n",
    "\n",
    "class BiLSTM_Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_mfcc: int,\n",
    "                 num_classes: int,\n",
    "                 lstm_hidden: int = 128,\n",
    "                 lstm_layers: int = 2,\n",
    "                 bidirectional: bool = True,\n",
    "                 lstm_dropout: float = 0.2,\n",
    "                 d_model: int = 128,\n",
    "                 nhead: int = 4,\n",
    "                 num_layers: int = 2,\n",
    "                 dim_feedforward: int = 256,\n",
    "                 dropout: float = 0.3,\n",
    "                 max_len: int = 4096):\n",
    "        super().__init__()\n",
    "        self.n_mfcc = int(n_mfcc)\n",
    "        self.bidir = bool(bidirectional)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.n_mfcc,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=(lstm_dropout if lstm_layers > 1 else 0.0),\n",
    "            bidirectional=self.bidir\n",
    "        )\n",
    "        lstm_out = lstm_hidden * (2 if self.bidir else 1)\n",
    "        self.proj = nn.Linear(lstm_out, d_model)\n",
    "        self.posenc  = PositionalEncoding(d_model=d_model, max_len=max_len, dropout=dropout)\n",
    "        enc_layer    = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n",
    "                                                  dim_feedforward=dim_feedforward,\n",
    "                                                  dropout=dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B,T,n_mfcc] / [B,n_mfcc,T]\n",
    "        if x.dim() != 3:\n",
    "            raise ValueError(f\"Expected 3D input, got {tuple(x.shape)}\")\n",
    "        if x.shape[-1] == self.n_mfcc:\n",
    "            seq = x                                \n",
    "        elif x.shape[1] == self.n_mfcc:\n",
    "            seq = x.transpose(1, 2).contiguous()    \n",
    "        else:\n",
    "            raise ValueError(f\"Input last dim must be n_mfcc={self.n_mfcc}; got {tuple(x.shape)}\")\n",
    "\n",
    "        lstm_out, _ = self.lstm(seq)                \n",
    "        h = self.proj(lstm_out)                     \n",
    "        h = self.posenc(h)\n",
    "        h = self.encoder(h)\n",
    "        feat = h.mean(dim=1)\n",
    "        return self.head(feat)\n",
    "\n",
    "def build_model(arch: str, n_mfcc: int, num_classes: int) -> nn.Module:\n",
    "    arch = (arch or \"transformer\").lower()\n",
    "    if arch in (\"transformer\", \"mfcc_transformer\"):\n",
    "        return MFCC_Transformer(n_mfcc=n_mfcc, num_classes=num_classes)\n",
    "    elif arch in (\"bilstm_transformer\", \"bilstm+transformer\", \"lstm_transformer\"):\n",
    "        lstm_hidden  = globals().get(\"LSTM_HIDDEN\", 128)\n",
    "        lstm_layers  = globals().get(\"LSTM_LAYERS\", 2)\n",
    "        lstm_bidir   = globals().get(\"LSTM_BIDIR\", True)\n",
    "        lstm_dropout = globals().get(\"LSTM_DROPOUT\", 0.2)\n",
    "        return BiLSTM_Transformer(\n",
    "            n_mfcc=n_mfcc, num_classes=num_classes,\n",
    "            lstm_hidden=lstm_hidden, lstm_layers=lstm_layers,\n",
    "            bidirectional=lstm_bidir, lstm_dropout=lstm_dropout\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown ARCH: {arch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae64de6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T00:45:11.847343Z",
     "iopub.status.busy": "2026-01-06T00:45:11.846782Z",
     "iopub.status.idle": "2026-01-06T00:45:12.081798Z",
     "shell.execute_reply": "2026-01-06T00:45:12.080965Z"
    },
    "papermill": {
     "duration": 0.239945,
     "end_time": "2026-01-06T00:45:12.083172",
     "exception": false,
     "start_time": "2026-01-06T00:45:11.843227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import nullcontext\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "_params = mfcc_params_for_sr(SR)\n",
    "print(f\"[MFCC] SR={SR} -> n_fft={_params['n_fft']} win_length={_params['win_length']} hop_length={_params['hop_length']}\")\n",
    "mfcc = torchaudio.transforms.MFCC(\n",
    "    sample_rate=SR, n_mfcc=N_MFCC,\n",
    "    melkwargs={\n",
    "        \"n_mels\": N_MELS,\n",
    "        \"n_fft\": int(_params[\"n_fft\"]),\n",
    "        \"hop_length\": int(_params[\"hop_length\"]),\n",
    "        \"win_length\": int(_params[\"win_length\"]),\n",
    "        \"center\": True, \"f_min\": 0.0, \"f_max\": SR / 2\n",
    "    }\n",
    ").to(device)\n",
    "\n",
    "def _compute_feats_gpu(wav: torch.Tensor) -> torch.Tensor:\n",
    "    feats = mfcc(wav)                 \n",
    "    feats = feats.transpose(1, 2).contiguous()  \n",
    "    return feats\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, scheduler=None, grad_clip_norm=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    use_amp = (\"SCALER\" in globals()) and (SCALER is not None) and (device.type == \"cuda\")\n",
    "    amp_ctx = (torch.autocast(device_type=\"cuda\", dtype=AMP_DTYPE) if use_amp else nullcontext())\n",
    "\n",
    "    step_per_batch = (\n",
    "        scheduler is not None\n",
    "        and not isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau)\n",
    "    )\n",
    "\n",
    "    for wav, y in loader:  \n",
    "        wav = wav.to(device, non_blocking=NON_BLOCK).float()  \n",
    "        y   = y.to(device,   non_blocking=NON_BLOCK).long()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with amp_ctx:\n",
    "            feats  = _compute_feats_gpu(wav)  \n",
    "            logits = model(feats)\n",
    "            loss   = criterion(logits, y)\n",
    "\n",
    "        if use_amp:\n",
    "            SCALER.scale(loss).backward()\n",
    "            if grad_clip_norm is not None:\n",
    "                SCALER.unscale_(optimizer)\n",
    "                clip_grad_norm_(model.parameters(), max_norm=float(grad_clip_norm))\n",
    "            SCALER.step(optimizer)\n",
    "            SCALER.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            if grad_clip_norm is not None:\n",
    "                clip_grad_norm_(model.parameters(), max_norm=float(grad_clip_norm))\n",
    "            optimizer.step()\n",
    "\n",
    "        if step_per_batch:\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "\n",
    "    return float(total_loss) / float(len(loader.dataset))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion=None):\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    total_loss = 0.0\n",
    "    have_loss = criterion is not None\n",
    "\n",
    "    use_amp = (device.type == \"cuda\")\n",
    "    amp_ctx = (torch.autocast(device_type=\"cuda\", dtype=AMP_DTYPE) if use_amp else nullcontext())\n",
    "\n",
    "    for wav, y in loader:\n",
    "        wav = wav.to(device, non_blocking=NON_BLOCK).float()\n",
    "        y   = y.to(device,   non_blocking=NON_BLOCK).long()\n",
    "\n",
    "        with amp_ctx:\n",
    "            feats  = _compute_feats_gpu(wav)\n",
    "            logits = model(feats)\n",
    "            if have_loss:\n",
    "                total_loss += criterion(logits, y).item() * y.size(0)\n",
    "\n",
    "        pred = logits.argmax(dim=1)\n",
    "        all_true.extend(y.tolist())\n",
    "        all_pred.extend(pred.tolist())\n",
    "\n",
    "    acc = accuracy_score(all_true, all_pred)\n",
    "    f1  = f1_score(all_true, all_pred, average=\"macro\")\n",
    "    avg_loss = (float(total_loss) / float(len(loader.dataset))) if have_loss else None\n",
    "\n",
    "    return float(acc), float(f1), avg_loss, np.array(all_true, dtype=np.int64), np.array(all_pred, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1ee6e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T00:45:12.090817Z",
     "iopub.status.busy": "2026-01-06T00:45:12.090346Z",
     "iopub.status.idle": "2026-01-06T00:45:12.095466Z",
     "shell.execute_reply": "2026-01-06T00:45:12.094774Z"
    },
    "papermill": {
     "duration": 0.009992,
     "end_time": "2026-01-06T00:45:12.096616",
     "exception": false,
     "start_time": "2026-01-06T00:45:12.086624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "COMMIT_MODE = True\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "\n",
    "    if COMMIT_MODE:\n",
    "        kwargs[\"disable\"] = True\n",
    "    return _tqdm(*args, **kwargs)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "pd.set_option(\"display.max_colwidth\", 120)\n",
    "\n",
    "if COMMIT_MODE:\n",
    "    def _no_show(*args, **kwargs):\n",
    "        pass\n",
    "    plt.show = _no_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb505c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T00:45:12.104246Z",
     "iopub.status.busy": "2026-01-06T00:45:12.103787Z",
     "iopub.status.idle": "2026-01-06T03:40:42.356417Z",
     "shell.execute_reply": "2026-01-06T03:40:42.355138Z"
    },
    "papermill": {
     "duration": 10530.259024,
     "end_time": "2026-01-06T03:40:42.358746",
     "exception": false,
     "start_time": "2026-01-06T00:45:12.099722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io, sys, contextlib, os, time, numpy as np, pandas as pd, shutil, json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SR_LIST = sorted(set(int(s) for s in SR_LIST))\n",
    "\n",
    "ARCH = \"bilstm_transformer\"\n",
    "\n",
    "\n",
    "def _outdirs_for(SR: int):\n",
    "    root = Path(f\"/kaggle/working/kfold_outputs_sr{SR}\")\n",
    "    d_fold = root / \"per_seed_and_fold\"\n",
    "    d_sum  = root / \"summary\"\n",
    "    d_fold.mkdir(parents=True, exist_ok=True)\n",
    "    d_sum.mkdir(parents=True, exist_ok=True)\n",
    "    return root, d_fold, d_sum\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def mute_outputs(active: bool):\n",
    "    if not active:\n",
    "        yield\n",
    "    else:\n",
    "        buf = io.StringIO()\n",
    "        with contextlib.redirect_stdout(buf), contextlib.redirect_stderr(buf):\n",
    "            yield\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "USE_CUDA   = torch.cuda.is_available()\n",
    "device     = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "PIN_MEMORY = bool(USE_CUDA)\n",
    "NON_BLOCK  = bool(USE_CUDA)\n",
    "if not COMMIT_MODE:\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "AMP_ENABLE = USE_CUDA\n",
    "if AMP_ENABLE:\n",
    "    major_cc = torch.cuda.get_device_capability()[0]\n",
    "    AMP_DTYPE = torch.bfloat16 if major_cc >= 8 else torch.float16\n",
    "    try:\n",
    "        SCALER = torch.amp.GradScaler(device=\"cuda\") if AMP_DTYPE is torch.float16 else None\n",
    "    except Exception:\n",
    "        SCALER = torch.cuda.amp.GradScaler(enabled=(AMP_DTYPE is torch.float16))\n",
    "else:\n",
    "    AMP_DTYPE = None\n",
    "    SCALER = None\n",
    "\n",
    "results = []\n",
    "summary_rows = []\n",
    "efficiency_rows_global = []\n",
    "\n",
    "with mute_outputs(COMMIT_MODE):\n",
    "    for seed in SEEDS:\n",
    "        if not COMMIT_MODE:\n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(f\"Running SEED = {seed}\")\n",
    "            print(\"=\"*70)\n",
    "        set_seed(seed)\n",
    "\n",
    "        for sr in SR_LIST:\n",
    "            SR = int(sr)\n",
    "            ROOT_OUT, OUT_FOLD, OUT_SUMM = _outdirs_for(SR)\n",
    "            MAX_LENGTH = SR\n",
    "\n",
    "            _params = mfcc_params_for_sr(SR)\n",
    "            mfcc = torchaudio.transforms.MFCC(\n",
    "                sample_rate=SR, n_mfcc=N_MFCC,\n",
    "                melkwargs={\n",
    "                    \"n_mels\": N_MELS,\n",
    "                    \"n_fft\": int(_params[\"n_fft\"]),\n",
    "                    \"hop_length\": int(_params[\"hop_length\"]),\n",
    "                    \"win_length\": int(_params[\"win_length\"]),\n",
    "                    \"center\": True, \"f_min\": 0.0, \"f_max\": SR / 2\n",
    "                }\n",
    "            ).to(device)\n",
    "\n",
    "            # Select active noise path from earlier cell\n",
    "            active_noise = globals().get(\"ACTIVE_NOISE_PATH\", globals().get(\"NOISE_PATH\", None))\n",
    "\n",
    "            folds = build_kfold_loaders_generic(\n",
    "                all_samples, CLASS_TO_IDX,\n",
    "                n_splits=N_SPLITS, seed=seed,\n",
    "                batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
    "                noise_path=active_noise,\n",
    "                max_length=MAX_LENGTH, noise_prob=NOISE_PROB, snr_range=SNR_RANGE,\n",
    "                sr=SR, augment_mode=\"file_noise\"\n",
    "            )\n",
    "\n",
    "            for fd in folds:\n",
    "                fold_id     = fd[\"fold\"]\n",
    "                train_loader= fd[\"train_loader\"]\n",
    "                val_loader  = fd[\"val_loader\"]\n",
    "\n",
    "                RUN_NAME = f\"{ARCH}_seed{seed}_fold{fold_id}_sr{SR}\"\n",
    "                OUT_SUB  = str((ROOT_OUT / \"per_seed_and_fold\" / RUN_NAME).resolve())\n",
    "                os.makedirs(OUT_SUB, exist_ok=True)\n",
    "                BEST_CKPT = os.path.join(OUT_SUB, \"best_model.pth\")\n",
    "                BEST_FULL = os.path.join(OUT_SUB, \"best_full.pt\")\n",
    "                LAST_CKPT = os.path.join(OUT_SUB, \"last_model.pth\")\n",
    "\n",
    "                model = BiLSTM_Transformer(\n",
    "                    n_mfcc=N_MFCC, num_classes=len(SELECTED_CLASSES),\n",
    "                    lstm_hidden=LSTM_HIDDEN, lstm_layers=LSTM_LAYERS,\n",
    "                    lstm_dropout=LSTM_DROPOUT\n",
    "                ).to(device)\n",
    "                assert next(model.parameters()).is_cuda == USE_CUDA, \"Model belum di CUDA!\"\n",
    "                n_params = int(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "                optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "                total_steps = max(1, EPOCHS * len(train_loader))\n",
    "                scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                    optimizer, max_lr=1e-3, total_steps=total_steps\n",
    "                )\n",
    "                criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "                best_val_acc = -1.0\n",
    "                best_true = best_pred = None\n",
    "                current_best_ckpt_path = BEST_CKPT\n",
    "\n",
    "                history = []\n",
    "\n",
    "                for ep in range(1, EPOCHS+1):\n",
    "                    model.train()\n",
    "                    tr_loss_sum = 0.0\n",
    "                    n_train = 0\n",
    "                    ep_t0 = time.time()\n",
    "\n",
    "                    for wav, y in train_loader:\n",
    "                        wav = wav.to(device, non_blocking=NON_BLOCK).float()\n",
    "                        y   = y.to(device, non_blocking=NON_BLOCK).long()\n",
    "                        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                        if AMP_ENABLE:\n",
    "                            with torch.autocast(device_type='cuda', dtype=AMP_DTYPE):\n",
    "                                feats  = _compute_feats_gpu(wav)\n",
    "                                logits = model(feats)\n",
    "                                loss   = criterion(logits, y)\n",
    "                            if SCALER is not None:\n",
    "                                SCALER.scale(loss).backward()\n",
    "                                SCALER.step(optimizer)\n",
    "                                SCALER.update()\n",
    "                            else:\n",
    "                                loss.backward()\n",
    "                                optimizer.step()\n",
    "                        else:\n",
    "                            feats  = _compute_feats_gpu(wav)\n",
    "                            logits = model(feats)\n",
    "                            loss   = criterion(logits, y)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                        if scheduler is not None:\n",
    "                            scheduler.step()\n",
    "\n",
    "                        bs = y.size(0)\n",
    "                        tr_loss_sum += loss.item() * bs\n",
    "                        n_train += bs\n",
    "\n",
    "                    tr_loss = tr_loss_sum / max(1, n_train)\n",
    "                    val_acc, val_f1, val_loss, y_true, y_pred = evaluate(model, val_loader, criterion)\n",
    "\n",
    "                    if val_acc > best_val_acc:\n",
    "                        best_val_acc = float(val_acc)\n",
    "                        best_true = y_true.copy()\n",
    "                        best_pred = y_pred.copy()\n",
    "\n",
    "                        torch.save(model.state_dict(), BEST_CKPT)\n",
    "                        torch.save({\n",
    "                            \"epoch\": ep,\n",
    "                            \"model_state\": model.state_dict(),\n",
    "                            \"optimizer_state\": optimizer.state_dict(),\n",
    "                            \"scheduler_state\": scheduler.state_dict() if scheduler is not None else None,\n",
    "                            \"val_acc\": best_val_acc,\n",
    "                            \"sr\": SR,\n",
    "                            \"seed\": seed,\n",
    "                            \"fold\": fold_id,\n",
    "                            \"classes\": list(SELECTED_CLASSES),\n",
    "                            \"class_to_idx\": CLASS_TO_IDX,\n",
    "                            \"n_mfcc\": N_MFCC,\n",
    "                            \"arch\": ARCH,\n",
    "                            \"model_class\": model.__class__.__name__,\n",
    "                        }, BEST_FULL)\n",
    "                        current_best_ckpt_path = BEST_CKPT\n",
    "\n",
    "                    ep_time = time.time() - ep_t0\n",
    "                    throughput = float(n_train) / ep_time if ep_time > 0 else 0.0\n",
    "                    history.append({\n",
    "                        \"epoch\": ep,\n",
    "                        \"train_loss\": float(tr_loss),\n",
    "                        \"val_loss\": float(val_loss),\n",
    "                        \"val_acc\": float(val_acc),\n",
    "                        \"val_f1\": float(val_f1),\n",
    "                        \"epoch_time_sec\": float(ep_time),\n",
    "                        \"throughput_samples_per_sec\": float(throughput),\n",
    "                    })\n",
    "\n",
    "                    if (ep % 5 == 0 or ep == 1 or ep == EPOCHS) and not COMMIT_MODE:\n",
    "                        if USE_CUDA:\n",
    "                            gpu_mb = torch.cuda.memory_allocated() / 1e6\n",
    "                            print(f\"[SR={SR} | GPU {gpu_mb:.1f} MB]\", end=\" \")\n",
    "                        print(f\"Seed {seed} | Fold {fold_id} | Epoch {ep:02d} \"\n",
    "                              f\"| tr_loss={tr_loss:.4f} | va_loss={val_loss:.4f} \"\n",
    "                              f\"| va_acc={val_acc:.4f} | va_f1={val_f1:.4f} | ep_time={ep_time:.2f}s | thr={throughput:.1f}/s\")\n",
    "\n",
    "                torch.save(model.state_dict(), LAST_CKPT)\n",
    "\n",
    "                cm = confusion_matrix(best_true, best_pred, labels=list(range(len(SELECTED_CLASSES))))\n",
    "                cm_df = pd.DataFrame(cm, index=SELECTED_CLASSES, columns=SELECTED_CLASSES)\n",
    "                cm_path = os.path.join(OUT_FOLD, f\"cm_{ARCH}_seed{seed}_fold{fold_id}_sr{SR}.csv\")\n",
    "                cm_df.to_csv(cm_path)\n",
    "\n",
    "                hist_df = pd.DataFrame(history)\n",
    "                hist_csv = os.path.join(OUT_SUB, \"history.csv\")\n",
    "                hist_df.to_csv(hist_csv, index=False)\n",
    "\n",
    "                try:\n",
    "                    plt.figure(figsize=(8,5))\n",
    "                    plt.plot(hist_df[\"epoch\"], hist_df[\"train_loss\"], label=\"train_loss\")\n",
    "                    plt.plot(hist_df[\"epoch\"], hist_df[\"val_loss\"], label=\"val_loss\")\n",
    "                    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Loss Curve\"); plt.legend();\n",
    "                    plt.tight_layout(); plt.savefig(os.path.join(OUT_SUB, \"loss_curve.png\")); plt.close()\n",
    "\n",
    "                    plt.figure(figsize=(8,5))\n",
    "                    plt.plot(hist_df[\"epoch\"], hist_df[\"val_acc\"], label=\"val_acc\")\n",
    "                    plt.plot(hist_df[\"epoch\"], hist_df[\"val_f1\"], label=\"val_f1\")\n",
    "                    plt.xlabel(\"Epoch\"); plt.ylabel(\"Score\"); plt.title(\"Validation Metrics\"); plt.legend();\n",
    "                    plt.tight_layout(); plt.savefig(os.path.join(OUT_SUB, \"metrics_curve.png\")); plt.close()\n",
    "\n",
    "                    per_class_counts = cm_df.sum(axis=1).replace(0, np.nan)\n",
    "                    correct = np.diag(cm)\n",
    "                    recall = correct / per_class_counts.values\n",
    "                    err_rate = 1.0 - recall\n",
    "                    plt.figure(figsize=(10,5))\n",
    "                    plt.bar(cm_df.index, err_rate)\n",
    "                    plt.ylabel(\"Error rate (1 - recall)\"); plt.title(\"Error per Class\")\n",
    "                    plt.xticks(rotation=45, ha='right')\n",
    "                    plt.tight_layout(); plt.savefig(os.path.join(OUT_SUB, \"error_per_class.png\")); plt.close()\n",
    "\n",
    "                    plt.figure(figsize=(6,5))\n",
    "                    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "                    plt.title('Confusion Matrix'); plt.colorbar()\n",
    "                    tick_marks = np.arange(len(SELECTED_CLASSES))\n",
    "                    plt.xticks(tick_marks, SELECTED_CLASSES, rotation=45, ha='right')\n",
    "                    plt.yticks(tick_marks, SELECTED_CLASSES)\n",
    "                    plt.tight_layout(); plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
    "                    plt.savefig(os.path.join(OUT_SUB, \"confusion_matrix.png\")); plt.close()\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] Failed to plot curves/CM for seed={seed} fold={fold_id} SR={SR}: {e}\")\n",
    "\n",
    "                # ROC & PR curves\n",
    "                try:\n",
    "                    from sklearn.preprocessing import label_binarize\n",
    "                    from sklearn.metrics import roc_curve, auc, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "\n",
    "                    try:\n",
    "                        state = torch.load(current_best_ckpt_path, map_location=device)\n",
    "                        if isinstance(state, dict) and 'model_state' in state:\n",
    "                            model.load_state_dict(state['model_state'])\n",
    "                        else:\n",
    "                            model.load_state_dict(state)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    model.eval()\n",
    "\n",
    "                    y_true_list, y_score_chunks = [], []\n",
    "                    with torch.no_grad():\n",
    "                        for wav, y in val_loader:\n",
    "                            wav = wav.to(device, non_blocking=NON_BLOCK).float()\n",
    "                            feats = _compute_feats_gpu(wav)\n",
    "                            logits = model(feats)\n",
    "                            probs = torch.softmax(logits, dim=1).detach().cpu().numpy()\n",
    "                            y_score_chunks.append(probs)\n",
    "                            y_true_list.extend(y.numpy().tolist())\n",
    "\n",
    "                    y_true_np = np.array(y_true_list, dtype=np.int64)\n",
    "                    y_score_np = np.vstack(y_score_chunks) if y_score_chunks else np.zeros((0, len(SELECTED_CLASSES)))\n",
    "                    n_classes = len(SELECTED_CLASSES)\n",
    "                    if y_score_np.shape[0] > 0:\n",
    "                        y_bin = label_binarize(y_true_np, classes=list(range(n_classes)))\n",
    "                        fpr, tpr, roc_auc = {}, {}, {}\n",
    "                        for i in range(n_classes):\n",
    "                            fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_score_np[:, i])\n",
    "                            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "                        fpr['micro'], tpr['micro'], _ = roc_curve(y_bin.ravel(), y_score_np.ravel())\n",
    "                        roc_auc['micro'] = auc(fpr['micro'], tpr['micro'])\n",
    "                        roc_auc_macro = roc_auc_score(y_bin, y_score_np, average='macro', multi_class='ovr')\n",
    "\n",
    "                        plt.figure(figsize=(8,6))\n",
    "                        for i, name in enumerate(SELECTED_CLASSES):\n",
    "                            plt.plot(fpr[i], tpr[i], label=f\"{name} (AUC={roc_auc[i]:.3f})\")\n",
    "                        plt.plot([0,1],[0,1], 'k--', alpha=0.4)\n",
    "                        plt.plot(fpr['micro'], tpr['micro'], linestyle='--', label=f\"micro (AUC={roc_auc['micro']:.3f})\")\n",
    "                        plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\"); plt.title(\"ROC Curves (OvR)\")\n",
    "                        plt.legend(); plt.tight_layout(); plt.savefig(os.path.join(OUT_SUB, \"roc_curve.png\")); plt.close()\n",
    "\n",
    "                        auc_rows = ([{'class': SELECTED_CLASSES[i], 'roc_auc': float(roc_auc[i])} for i in range(n_classes)] +\n",
    "                                    [{'class': 'micro', 'roc_auc': float(roc_auc['micro'])},\n",
    "                                     {'class': 'macro', 'roc_auc': float(roc_auc_macro)}])\n",
    "                        pd.DataFrame(auc_rows).to_csv(os.path.join(OUT_SUB, \"roc_auc_summary.csv\"), index=False)\n",
    "\n",
    "                        precision, recall, ap = {}, {}, {}\n",
    "                        for i in range(n_classes):\n",
    "                            precision[i], recall[i], _ = precision_recall_curve(y_bin[:, i], y_score_np[:, i])\n",
    "                            ap[i] = average_precision_score(y_bin[:, i], y_score_np[:, i])\n",
    "                        precision['micro'], recall['micro'], _ = precision_recall_curve(y_bin.ravel(), y_score_np.ravel())\n",
    "                        ap_micro = average_precision_score(y_bin, y_score_np, average='micro')\n",
    "                        ap_macro = average_precision_score(y_bin, y_score_np, average='macro')\n",
    "\n",
    "                        plt.figure(figsize=(8,6))\n",
    "                        for i, name in enumerate(SELECTED_CLASSES):\n",
    "                            plt.plot(recall[i], precision[i], label=f\"{name} (AP={ap[i]:.3f})\")\n",
    "                        plt.plot(recall['micro'], precision['micro'], linestyle='--', label=f\"micro (AP={ap_micro:.3f})\")\n",
    "                        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall Curves (OvR)\")\n",
    "                        plt.legend(); plt.tight_layout(); plt.savefig(os.path.join(OUT_SUB, \"pr_curve.png\")); plt.close()\n",
    "\n",
    "                        ap_rows = ([{'class': SELECTED_CLASSES[i], 'average_precision': float(ap[i])} for i in range(n_classes)] +\n",
    "                                   [{'class': 'micro', 'average_precision': float(ap_micro)},\n",
    "                                    {'class': 'macro', 'average_precision': float(ap_macro)}])\n",
    "                        pd.DataFrame(ap_rows).to_csv(os.path.join(OUT_SUB, \"pr_ap_summary.csv\"), index=False)\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] Failed to compute PR/ROC curves for seed={seed} fold={fold_id} SR={SR}: {e}\")\n",
    "\n",
    "                total_time = float(hist_df[\"epoch_time_sec\"].sum()) if not hist_df.empty else 0.0\n",
    "                avg_ep_time = float(hist_df[\"epoch_time_sec\"].mean()) if not hist_df.empty else 0.0\n",
    "                mean_thr = float(hist_df[\"throughput_samples_per_sec\"].mean()) if not hist_df.empty else 0.0\n",
    "                efficiency_rows_global.append({\n",
    "                    \"sr\": SR,\n",
    "                    \"seed\": seed,\n",
    "                    \"fold\": fold_id,\n",
    "                    \"arch\": ARCH,\n",
    "                    \"n_params\": n_params,\n",
    "                    \"epochs\": EPOCHS,\n",
    "                    \"total_time_sec\": total_time,\n",
    "                    \"avg_epoch_time_sec\": avg_ep_time,\n",
    "                    \"mean_throughput_samples_per_sec\": mean_thr,\n",
    "                })\n",
    "\n",
    "                results.append({\n",
    "                    \"seed\": seed,\n",
    "                    \"fold\": fold_id,\n",
    "                    \"sr\": int(SR),\n",
    "                    \"val_acc\": float(best_val_acc),\n",
    "                    \"cm_path\": cm_path,\n",
    "                    \"ckpt_path\": current_best_ckpt_path,\n",
    "                })\n",
    "\n",
    "        for sr0 in SR_LIST:\n",
    "            accs = [r[\"val_acc\"] for r in results if r[\"seed\"] == seed and r[\"sr\"] == int(sr0)]\n",
    "            if accs:\n",
    "                summary_rows.append({\n",
    "                    \"seed\": seed,\n",
    "                    \"sr\": int(sr0),\n",
    "                    \"acc_mean_over_folds\": float(np.mean(accs)),\n",
    "                    \"acc_std_over_folds\":  float(np.std(accs)),\n",
    "                    \"n_folds\": N_SPLITS\n",
    "                })\n",
    "\n",
    "if efficiency_rows_global:\n",
    "    eff_df = pd.DataFrame(efficiency_rows_global)\n",
    "    for SR in sorted(set(eff_df[\"sr\"].tolist())):\n",
    "        ROOT_OUT, OUT_FOLD, OUT_SUMM = _outdirs_for(SR)\n",
    "        eff_df_sr = eff_df[eff_df[\"sr\"] == int(SR)].copy()\n",
    "        if not eff_df_sr.empty:\n",
    "            eff_df_sr.to_csv(OUT_SUMM / f\"{ARCH}_speed_efficiency_per_fold_sr{SR}.csv\", index=False)\n",
    "            agg = (\n",
    "                eff_df_sr.groupby([\"seed\"]).agg({\n",
    "                    \"total_time_sec\": \"sum\",\n",
    "                    \"avg_epoch_time_sec\": \"mean\",\n",
    "                    \"mean_throughput_samples_per_sec\": \"mean\",\n",
    "                    \"fold\": \"count\"\n",
    "                }).rename(columns={\"fold\": \"n_folds\"}).reset_index()\n",
    "            )\n",
    "            agg.to_csv(OUT_SUMM / f\"{ARCH}_speed_efficiency_per_seed_sr{SR}.csv\", index=False)\n",
    "\n",
    "if not COMMIT_MODE:\n",
    "    print(\"\\nTraining selesai.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6666857,
     "sourceId": 10749559,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10552.858968,
   "end_time": "2026-01-06T03:40:45.081796",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-06T00:44:52.222828",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
